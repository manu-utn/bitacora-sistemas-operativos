#+TITLE: Concurrencia y Sincronización
* Cuestionario
  
* conceptos q dijo nano (utnianos)
semaforos-> se usan para coordinar los hilos
tipos: binario (0 y 1) que funciona entre procesos
mutex(0,1) funciona en el mismo proceso
contador(0 hasta n recursos) puede ser compartido entre procesos
* repaso clase anterior
** monohilo
** multhilo
** pcb 
   imagen, pila, stack, datos, pcb
** multihilo
** tcb
   bloque de control del hilo
   informacion sobre ese hilo en particular
   se podia compartir entre los distintos hilos
** estados y planificacion de hilos
** ventajas hilos
   los hilos no dependen de otros hilos
   para seguir ejecutandose
   
   un proceso con muchos hilos
   ocupa menos espacio

   un proceso con muchos procesos
   ocupa mas espacio xq se comparten

   cada hilo tiene su propio estado
** ult y klt
*** ult
    ult son hilos a nivel usuario
    administrado por una biblioteca de usuarios
    (no es una biblioteca estandar)
    permiten planificar los hilos de una manera dif.
    a como lo hace el SO (usar prioridades diferentes)

    permitian *portabilidad* para pasar a cualquier SO
    y funcione de la misma forma

    desventajas..
    si uno se bloquea, el proceso se bloquea
*** klt
    hilos del SO,
    el SO es el encargado de administrar los hilos
    (por el planificador del SO)
    
    cuando un hilo se bloquea, los otros se pueden
    seguir  ejecutando porque el SO los conoce
** arquitecturas de kernel
*** microkernel
    se saca toda la funcionalidad que no esté
    relacionada con el kernel

    mas facil de administrar, menos eficientes,
    mas estables
*** estructura monolitica
    los SO la suelen usar por eficiencia
* Sincronización
** Condición de carrera
*** Conceptos
    - Cuando varios procesos/hilos usan el mismo recurso (datos compartidos concurrentemente)
    - Interviene la *velocidad relativa* de los procesos, esto produce comportamientos no deseados
      
    #+BEGIN_COMMENT
    el orden en que se ejecuten los hilos depende del *planificador*
    #+END_COMMENT

   #+BEGIN_EXAMPLE
   Un ejemplo sería cuando en un proceso, varios hilos
   intentan modificar el valor de una variable
   (uno la decrementa, otra la decrementa, o hacen la misma operación)
   y en un momento el resultado NO es el esperado
   #+END_EXAMPLE
*** Solución
    Hay que *sincronizar* los hilos, para asegurar que solo UN proceso/hilo 
    pueda acceder a esos datos compartidos (recursos)
** [DONE] Sección crítica
   CLOSED: [2021-09-26 dom 21:08]
*** [DONE] Conceptos
    CLOSED: [2021-09-25 sáb 00:31]
   - Es el problema que presenta la [[Condición de Carrera]]
     (varios procesos/hilos usan el mismo recurso, y este se vuelve inconsistente)
   
   #+BEGIN_EXAMPLE
   Un ejemplo de recurso podría ser una variable global
   #+END_EXAMPLE
*** [DONE] Como debe ser
    CLOSED: [2021-09-25 sáb 00:31]
    La sección crítica debería 
    + ser _lo más chica_ posible
    + ejecutarse en forma *atómica*
      (Similar al concepto de las *transacciones* de GDD,
       que todas las operaciones se ejecuten como una sola) 
*** [DONE] Protocolo para acceder
    CLOSED: [2021-09-25 sáb 00:31]
    Para evitar problemas en la sección crítica, se podría seguir el siguiente orden
    
   |-------+--------------------+--------------------------------------------------------------|
   | ORDEN |                    |                                                              |
   |-------+--------------------+--------------------------------------------------------------|
   |   1   | SECCION DE ENTRADA | _Pedimos permiso para acceder_ a la sección crítica          |
   |-------+--------------------+--------------------------------------------------------------|
   |   2   | SECCION CRITICA    | Solo _un proceso por vez_ puede acceder a su sección crítica |
   |-------+--------------------+--------------------------------------------------------------|
   |   3   | SECCION DE SALIDA  | _Se libera_ la sección crítica                               |
   |       |                    | y permitimos a los otros procesos entrar                     |
   |-------+--------------------+--------------------------------------------------------------|
*** [DONE] Cuando sucede
    CLOSED: [2021-09-25 sáb 00:31]
    + Más de un proceso/hilo usa el mismo recurso (ó _alguno lo está modificando_ al recurso compartido)
    + Los accesos al recurso son de *forma concurrente*
*** [DONE] Condiciones de Bernstein
    CLOSED: [2021-09-25 sáb 00:53]
    + Herramienta para saber _cuando conviene sincronizar los procesos_
    + Utiliza *teoria de conjuntos* con las operaciones ~(R)ead~ y ~(W)rite~
    + Evalúan el resultado de la intersección entre esas dos operaciones
      * Si es { } (conjunto vacío): NO necesitamos sincronizar los procesos
      * si NO  es { }, se aplica lo de codigo de entrada/salida
*** [DONE] Requerimientos para la solución
    CLOSED: [2021-09-25 sáb 00:53]
**** Exclusión Mutua
     Que solo 1 proceso pueda acceder a su sección crítica a la vez
     (esto aplica tanto para lectura/escritura)  

     #+BEGIN_EXAMPLE
     Digamos que si un hilo está insertando nodos, que solo ese lo haga y punto
     
     Si un proceso está haciendo una lectura, y otro escritura
     ambos de forma "concurrente" (de forma intercalada, uno, el otro, ...)
     también podría haber problemas deberían realizar esas operaciones de "forma sincronizada" (coordinada)
     #+END_EXAMPLE
**** Progreso
     Si la sección está disponible, que cualquier proceso ó hilo pueda acceder
**** Espera limitada
     Que un proceso no deba esperar tanto tiempo evita la *inanición* (starvation)
**** Velocidad Relativa
     No se sabe en que orden se ejecutaran los procesos, ó cuando se finalizará un proceso
     NO hacer suposiciones
*** [DONE] Soluciones a esos requerimientos
    CLOSED: [2021-09-27 lun 18:06]
**** de Software
***** Conceptos
      Son "intentos" de soluciones desarrolladas por programadores para
      resolver la entrada/salida a la *sección crítica* (asegurarla)
      e "intentaban" cumplir con los [[Requerimientos para la solución]]
***** [DONE] Primer intento de solución
      CLOSED: [2021-09-18 sáb 09:14]
      #+NAME: validacion-requerimientos 
      |--------------------+---------+----------------------------------------------------------------------|
      | Requerimiento      | Cumple? | Motivo                                                               |
      |--------------------+---------+----------------------------------------------------------------------|
      | Exclusión Mutua    | SI      |                                                                      |
      |--------------------+---------+----------------------------------------------------------------------|
      | Progreso           | NO      | - La variable ~turno~ BLOQUEA a alguno de los procesos               |
      |                    |         | - Impide que uno se pueda ejecutar varias veces seguidas             |
      |                    |         | - Uno de los procesos espera que se cambie a 0 ó 1                   |
      |                    |         | para ser usado. Sólo uno puede ejecutarse por vez.                   |
      |--------------------+---------+----------------------------------------------------------------------|
      | Espera Activa      | SI      | Se trata de evitar, porque consume CPU/procesamiento                 |
      |--------------------+---------+----------------------------------------------------------------------|
      | Velocidad Relativa | NO      | NO, porque un proceso no puede acceder a la SC varias veces seguidas |
      |                    |         | debe esperar que el otro proceso se lo permita                       |
      |--------------------+---------+----------------------------------------------------------------------|

      + *Ventaja*: Hay prioridad, de quien se ejecutará primero o después
      + *Desventaja:* Si otro proceso está interesado en ejecutar no puede, hasta que termine 
        el que está ejecutando

      *IMPORTANTE..!*
      La *sección entrada* en esta solución abarca tanto el ~while(true)~ y ~turno=1~ 
      porque es TODO lo que estoy tratando de hacer poder ingresar a la 
      [[Sección Crítica]]
        
      #+BEGIN_SRC C
        int turno = 0; // recurso que van a compartir el proceso 0 y 1

        // proceso 0
        while(true){
          while(turno != 0); // esto es "espera activa" loopea no haciendo nada mientras se cumple
          // seccion critica
          turno = 1; // codigo de salida

          // sección restante
        }
        /***** cuando finaliza el proceso anterior => el otro continua  *****/

        // proceso 1
        while(true){
          while(turno != 1); // esto es "espera activa" loopea no haciendo nada mientras se cumple
          // seccion critica
          turno = 0; // codigo de salida

          // sección restante
        }
      #+END_SRC
***** [DONE] Segundo intento de solución
      CLOSED: [2021-09-18 sáb 09:21]
      #+BEGIN_COMMENT
      En clase DAN dijo que este NO cumplia con exclusión mutua,
      pero si con progreso (???), osea sería un """si"" entre muchas comillas,
      siempre y en cuando ambos no estén interesados al mismo tiempo, no?

      Rta: NO, igual cumplen mutua exclusión
      #+END_COMMENT

      #+NAME: validacion-requerimientos 
      |-----------------+---------+--------------------------------------------------------------|
      | Requerimiento   | Cumple? | Motivo                                                       |
      |-----------------+---------+--------------------------------------------------------------|
      | Exclusión Mutua | SI      |                                                              |
      |-----------------+---------+--------------------------------------------------------------|
      | Progreso        | NO      | Puede generar que NINGUNO de los dos procesos pueda          |
      |                 |         | acceder a la *sección crítica* y se quedan en el ~while(1)~  |
      |                 |         | (si ambos estan interesados, NO sabe cual priorizar)         |
      |-----------------+---------+--------------------------------------------------------------|
      | Espera Activa   | SI      | Se trata de evitar, porque consume CPU/procesamiento         |
      |-----------------+---------+--------------------------------------------------------------|
      | Velocidad       | SI      | Porque uno de los procesos que esté interesado puede acceder |
      |                 |         | a la SC varias veces seguidas                                |
      |-----------------+---------+--------------------------------------------------------------|

      + *Ventaja*: Si un proceso está ejecutando, y otro también quiere entonces uno se detiene y sigue el otro
      + *Desventaja:* NO hay prioridad, si ambos están interesados en ejecutar
      
      *IMPORTANTE..!*
      La *sección entrada* en esta solución abarca tanto el ~while(true)~ y ~interesado[0]=true~ 
      porque es TODO lo que estoy tratando de hacer poder ingresar a la 
      [[Sección Crítica]]
      
      #+BEGIN_SRC C
        int interesado[] = {false, false};

        // Proceso 0
        //
        while(true){
          interesado[0] = true;
          while(interesado[1]); // pregunta si otro está interesado, permite que el otro siga
          // seccion critica
          interesado[0] = false;
          // seccion restante
        }

        /***** cuando finaliza el proceso anterior => el otro continúa ******/

        // Proceso 1
        //
        while(true){
          interesado[1] = true;
          while(interesado[0]); // pregunta si hay alguien interesado, permite que el otro siga
          // seccion critica
          interesado[1] = false;
          // seccion restante
        }
      #+END_SRC
***** [TODO] tercer intento
***** [TODO] cuarto intento
***** Soluciones que SI funcionan
      Ambos tienen *espera activa* que es algo NO deseable, pero resuelven el problema
****** Algoritmo de Dekker
****** [DONE] Algoritmo de Peterson (Interesados+Turnos)
       CLOSED: [2021-09-18 sáb 09:21]
       
      |--------------------+---------+-----------------------------------------------------------------|
      | Requerimiento      | Cumple? | Motivo                                                          |
      |--------------------+---------+-----------------------------------------------------------------|
      | Exclusión Mutua    | SI      |                                                                 |
      |--------------------+---------+-----------------------------------------------------------------|
      | Progreso           | SI      | Porque si la SC solo se usa para el proceso que esté interesado |
      |                    |         | y sea su turno, si no lo es le da lugar al otro proceso         |
      |--------------------+---------+-----------------------------------------------------------------|
      | Velocidad Relativa | SI      | Porque si el proceso está interesado y es su turno              |
      |                    |         | puede acceder a la SC varias veces seguidas                     |
      |--------------------+---------+-----------------------------------------------------------------|
      | Espera Activa      | SI      | Se trata de evitar, porque consume CPU/procesamiento            |
      |--------------------+---------+-----------------------------------------------------------------|

      *IMPORTANTE...!*
      La *sección entrada* en esta solución abarca tanto el ~while(true)~ como ~interesado[0]=true~ y también ~turno=1~
      porque es TODO lo que estoy tratando de hacer poder ingresar a la 
      [[Sección Crítica]]

      #+BEGIN_SRC C
        // Sólo habría que decidir cual de los procesos debe empezar
        int interesado[] = {false, false};
        
        // Proceso 0
        //
        while(true){
          interesado[0] = true;               // Seccion entrada
          turno = 1;                          // Seccion Entrada
          while(interesado[1] && turno == 1); // Seccion entrada
        
          // Si el otro proceso está interesado y tiene igual prioridad (turno = 1)
          // entonces se queda loopeando "no haciendo nada" hasta
          // que ese otro cambie su prioridad (turno = 0)
        
          // seccion critica
          interesado[0] = false;
          // seccion restante
        }
        
        // Proceso 1
        //
        while(true){
          interesado[1] = true;
          turno = 0;
        
          // Si el otro proceso está interesado y tiene igual prioridad (turno = 0)
          // entonces se queda loopeando "no haciendo nada" hasta...
          // que ese otro cambie su prioridad
          while(interesado[0] && turno == 0);
          // seccion critica
          interesado[1] = false;
          // seccion restante
        }
      #+END_SRC
**** [DONE] de Hardware
     CLOSED: [2021-09-27 lun 18:04]
***** Deshabilitar Interrupciones
      - Evita que las instrucciones de la [[Sección Crítica]] sean *interrumpidas* con las de otros procesos.
      - Son *instrucciones privilegiadas*
      - Se deshabilitan antes de entrar a la SC

      #+BEGIN_QUOTE
      Las interrupciones van a seguir ocurriendo igual, solo se van a demorar su atención como si las encolaran
      una vez que salió de la SC, se vuelven a habilitar y se atienden a las interrupciones
      #+END_QUOTE

      #+BEGIN_COMMENT
      Entonces las interrupciones se encolarian cuando se deshabilitan? en donde?

      *Rta:* Se encolarian, y se atenderían según su prioridad, y NO se ejecutaría ninguna instrucción
      hasta que se termine de atender esas instrucciones
      #+END_COMMENT
       
      *Ventajas:*
      - NO permite que se cambie de proceso una vez que esta en la Sección Crítica

      *Desventajas:*
       - Desactivar las interrupciones en todos los procesadores, genera overhead
       - NO es bueno para sistemas con *multiprocesadores*
***** TestAndSet - Instrucciones Atómicas
      + Sufre *espera activa* <---
      + Soluciona el problema del *deshabilitar interrupciones* (el overhead)
      + El preguntar si se puede ingresar en la sección critica se hará en una instrucción,
         en un *ciclo de instrucción* que nos asegura que NO se va a interumpir
         (es atómica, como una transacción de SQL)
      + Son sencillos de usar, y sirven para sistemas con multiprocesadores
      + Los ~while~ de ambos procesos generan *espera activa*
      + No cumple con la portabilidad, porque depende de la arquitectura del procesador
      
      #+BEGIN_SRC C
        // SET_AND_TEST: funcion provista por el PROCESADOR
        //
          BTS(*lock){ // test_and_set
            // lock es el RECURSO COMPARTIDO
            if (*lock == false){
              ,*lock = true;
              return true;
            }else
              return false;
          }

          lock = false; // ARRANCA ASI
          // Obs: no interesa por cual proceso empieza

          // Proceso (0)
          //
          while(!BTS(&lock)); // mientras ningun proceso lo esté utilizando
          // Sección critica
          lock = false;
          // Sección restante

          /******************************************/

          // Proceso (1)
          //
          lock = true;
          while(!BTS(&lock)); // mientras ningun proceso lo esté utilizando
          // Sección critica
          lock = false;
          // Sección restante
      #+END_SRC
**** de Sistema Operativo
     Semáforos
* Concurrencia
** Interacción entre procesos
*** Comunicación entre procesos
*** Competencia de los procesos por los recursos
    Independientemente entre los procesos que hayan alrededor
*** Cooperación de los procesos
    - Vía recursos compartibles
    - Vía comunicación
      (/mandarse mensaje entre si, para sincronizarse/)

    #+BEGIN_QUOTE
    Un ejemplo común de cooperación inter-procesos con recursos compartibles,
    es cuando varios hilos que comparten un recurso (Ej. una variable del tipo entera)
    para persistir los resultados de operaciones ariméticas.
   
    Si hay un acceso concurrente a esa variable entera compartida (varios procesos se pelean por acceder)
    entonces el valor que contenga la variable "quizás" no sea del todo certero, 
    no siendo el valor esperado..

    Es decir a veces, tendría un comportamiento no determinístico,
    se esperaba que ante ciertas operaciones A,B,C el resultado sea D
    pero el valor final resultante era Z en vez de D
    #+END_QUOTE

** Seccion crítica
   Un proceso debe estar en esta sección lo menos posible
*** Soluciones
    Se utiliza un concepto de *fifo* se van encolando los hilos que quieren acceder
    y se turnan para modificar
**** Código de entrada (en seccion critica)
**** Código de salida (en seccion critica)
** Semáforos (Solución de SO)
*** [DONE] Conceptos
    CLOSED: [2021-09-26 dom 21:38]
    + Se llaman *mutex* a los semáforos que solucionan el problema de la [[Sección Crítica]]
    + Permite *exclusión mutua* entr varios procesos
    + Permite *Sincronizar* (u ordenar) varios procesos
    + Pemite *controla acceso* a recursos
    + Se acceden a ellos mediante las syscalls ~wait~ y ~signal~ (son funciones atómicas)
      - ~signal~ como salida
      - ~wait~ como entrada
    + Se pueden implementar
      1. con *espera activa* (/no es muy eficiente, genera overhead porque se queda en un while(1) preguntando a cada rato/)
      2. sin *espera activa* (/por default, el SO bloquea los procesos asociados al semáforo, esperando para entrar a la SC/)

    #+BEGIN_QUOTE
    Por default el valor de un semáforo es 1, porque considera la *mutua exclusión*
    es decir sólo 1 proceso a la vez puede acceder a este.
    #+END_QUOTE

    #+BEGIN_COMMENT
    Por default el valor es 1 (pudiendo ser un semáforo binario/mutex)

    si el valor es mayor a 1 (es semáforo contador)
    se debe evaluar usar lock?
    #+END_COMMENT

    |------------------|
    | SEM = 1          |
    | ...              |
    |                  |
    | ~WAIT(SEM)~      |
    |                  |
    | SECCIÓN CRITICA  |
    |                  |
    | ~SIGNAL(SEM)~    |
    |                  |
    | SECCION RESTANTE |
    |------------------|

    *Observación:*
    Se inicializar con valor positivo o cero, pero NUNCA pueden inicializarse en valor negativo
*** Estructura
    - un valor entero
    - una lista de procesos bloqueado
*** [DONE] Funciones
    CLOSED: [2021-09-26 dom 21:48]
**** wait
      - decrementa en 1 el valor del semaforo
**** signal
     - incrementa en 1 el valor del semaforo
**** [DONE] Ejemplo - Con espera activa
     CLOSED: [2021-09-26 dom 21:38]
     - NO es muy eficiente, genera overhead
     - El proceso se queda en un loop infinito preguntando si puede acceder a la SC

     #+BEGIN_SRC C
       // va  estar inicializado en 1, sem = 1
       wait(sem){
         // siempre que esté en cero, es porque alguien ya lo tomó
         // y se queda loopeando sin hacer nada mientras (idle/ancioso)+overhead
         while(sem == 0);

         sem--;
       }

       signal(sem){
         sem++;
       }
     #+END_SRC
**** [DONE] Ejemplo - Con bloqueo
     CLOSED: [2021-09-26 dom 21:38]
     - La opción por default que implementa el (SO)

     #+BEGIN_SRC C
       wait (S){
         valor--;
       
         // si se cumple, alguien lo está utilizando
         if(valor < 0){
           // - entonces bloqueamos al proceso/hilo (en realidad el SO lo hace)
           // - cola de espera del semáforo
           block();
         }
       }
       
       signal (S){
         valor++;
       
         // si se cumple, alguno de los procesos estaba bloqueado
         if(valor <= 0){
           // entonces, lo volvemos a poner en Ready
           // pero cuando el "planificador" decida
           // avanzará a la "sección crítica"
           //
           // - despierta al primer proceso que se bloqueó/que estaba en espera
           // - respeta el orden en que fueron bloqueados los procesos, en forma FIFO
           // - se podría evaluar otro orden que no sea FIFO
           wakeup(pid);
         }
       }
     #+END_SRC
**** Ejemplo 1
     + cuando el valor es negativo..
     + cuando es positivo..

     #+BEGIN_SRC C
       // s = semaforo

       // no genera espera activa
       wait(s){ // 
         // al valor del semaforo
         x->valor--; //
         if(s->valor < 0)
           bloquear(pid, s->lista);
       }

       // no genera espera activa
       signal(s){
         x->valor++; // al valor del semaforo

         if(s->valor <= 0)
           pid = despertar(pid, s->lista); // desbloqueo cualquier proceso
       }
     #+END_SRC
*** [DONE] Cuando implementar - con Espera activa
    CLOSED: [2021-09-26 dom 21:48]
    Las situaciones que pueden ser mas eficiente usar ~pthreads_spinlocks_t~ serían
    + Cuando hay más de 1 CPU (/sistema multiprocesador/)
    + Cuando la *Sección Crítica* es chica (//)

    #+BEGIN_QUOTE
    El proceso en "espera activa" continúa su ejecución más rápido,
    nos ahoramos el bloqueo/desbloqueo y los cambios de contexto
    #+END_QUOTE
*** [DONE] Tipos de semáforos
    CLOSED: [2021-09-26 dom 21:58]
**** General o Contador
     - se inicializan _con un valor positivo_ ~N~ (/N cant. de instancias/)
     - permite _controlar el acceso_ a una cantidad de recursos (/N instancias/)
     - para *proteger recursos*

     #+BEGIN_QUOTE
     Cualquier instancia ~x~ de un recurso le sirve al proceso que lo necesita

     Ej. si tenemos 4 instancias del recurso impresora,
     podemos inicilizar la vaiable que usará el *semáforo contador* con ~IMPRESORAS_DISPONIBLES=4~

     donde cada proceso que ejecute ~imprimir()~ puede usar cualquiera de esas 4 instancias,
     suponiendo que estén disponibles, ya que por cada proceso que lo solicite hará ~wait()~
     del *semáforo contador* decrementando en 1 la cant. de instancias de impresoras

     si el valor del semáforo es negativo, ej. ~IMPRESORAS_DISPONIBLES=-10~
     es porque hay 10 procesos bloqueados, esperando a usar alguna de las instancias de impresora,

     cuando alguno de los procesos deje de usar alguna de las instancias, hará un ~signal()~
     del *semáforo contador* incrementando en 1 la cant. de instancias de impresoras,
     pudiendo que en algun momento otro proceso pueda usarlas
     #+END_QUOTE
**** Binario
      + garantiza un _orden de ejecución_
      + similar al anterior, pero NO sabemos cuantos recursos podemos tener asignados
      + se puede usar para *sincroniza*
      + entre los valores 0 y 1
      + representa a dos estados
        1. estado libre
        2. estado ocupado
**** Mutex
     - SOLO puede _inicializarse en 1_
     - Soluciona el problema de *Exclusión Mutua*
     - Es un tipo *semáforo binario*
*** [DONE] Inicialización de un semáforo
    CLOSED: [2021-09-26 dom 22:04]
    Suelen iniciarse en 0 o positivos
    
    Si inicializamos en 0 (cero), es porque _estamos esperando un evento_
    que haga ~signal~ para que pueda avanzar

    Si lo inicializams con un valor n > 0, seria porque es una
    *semaforo contador* y que tiene n cantidad de recursos disponibles
    
    NO se puede inicializar con un valor negativo
*** [DONE] Valores de un semáforo
    CLOSED: [2021-09-26 dom 22:04]
    |--------------------+-------------------------------------------------------------------------------------|
    | Valor del semaforo | Indica                                                                              |
    |--------------------+-------------------------------------------------------------------------------------|
    | positivo (> 0)     | cantidad de recursos disponibles de un *Semáforo contador*                          |
    |--------------------+-------------------------------------------------------------------------------------|
    | negativo (< 0)     | - cantidad de procesos bloqueados esperando a acceder a una instancia de un recurso |
    |                    | - cantidad de procesos en la cola de espera/bloqueados                              |
    |                    | - la *sección crítica* está en uso                                                  |
    |--------------------+-------------------------------------------------------------------------------------|
*** Implementación - Problemas del semaforos
    - que existe una *variable compartida* (Ej. s)
    - requiere *exclusión mutua*
      - soluciones de software
      - soluciones de hardware
*** [DONE] Implementación - Biblioteca Pthreads
    CLOSED: [2021-09-26 dom 21:42]
     + Con espera activa =>  ~phtreads_spinlock_t~
     + Con bloqueo => ~phtreads_mutex_t~

     Ambos utilizan el concepto de ~lock(wait)~ y ~unlock(signal)~
*** [DONE] Utilidad
    CLOSED: [2021-09-26 dom 22:35]
**** Exclusion mutua
     Definimos un *mutex* (semáforo) para cada uno de los *recursos compartidos*
     si hay un posible problema de [[Condición de carrera]]
     y accedemos a él de forma [[Sincronización][Sincronizada]]

     #+BEGIN_SRC C
       semVar = 1;

       // Proceso (1)
       wait(semVar);      // 1. lo pedimos
       var++;             // 2. lo usamos
       signal(semVar);    // 3. lo liberamos


       // Proceso (2)
       wait(semVar);
       var--;
       signal(semVar);
     #+END_SRC
**** Limitar Acceso a recursos (N instancias)
     Definimos un *semáforo contador* limitando el acceso a la cant. de instancias

     #+BEGIN_SRC C
       // lo inicializamos en N
       semContador = N; // cant. total de recursos

       // Proceso (1)
       wait(semContador);   // 1. pedimos el recurso  (entrada) <- hará semContador--
       usarRecurso();       // 2. lo usamos
       signal(semContador); // 3. lo liberamos (salida) <- hará semContador++

       // Proceso (2)
       wait(semContador); // <- hará semContador--
       usarRecurso();
       signal(semContador);
     #+END_SRC
**** Ordenar ejecución (Sincronizar)
     Utilizamos los *semáforos binarios*
     + cuando tenemos varios semaforos
     + puede no haber *sección crítica*
     + aparecen los *semaforos cruzados*

     En este caso los ~signal()~ los cruzamos,
     uno de los procesos espera al otro

     #+BEGIN_SRC C
       semP1 = 1;
       semP2 = 0; // Alguno de esos debe inicializarse en 0 (cero) para que uno comience, y active al otro
       
       // Proceso (1) - dar la bienvenida
       while(1){
         // como este semáforo está inicializado en 1, pasará a la SC y hará sem--
         wait(semP1); // espera a este semaforo para avanzar
       
         printf("bienvenido!");
      
         // - le avisará al proceso que esté bloqueado esperando que este semáforo se desbloquee
         // - actúa como un wakeup(proceso) 
         signal(semP2);
       }
       
       /*******************************/
       
       // Proceso (2) - despedirse
       while(1){
         wait(semP2); // espera a este semaforo para avanzar
       
         printf("hasta luego!");
       
         signal(semP1);
        }
     #+END_SRC
*** [DONE] Productor - Consumidor
    CLOSED: [2021-09-26 dom 22:34]
**** Conceptos
     Aparecen 
     - productor
     - consumidor
     - buffer compartido
**** Ejemplo 1 - Semaforo Mutex - Condición de Carrera - Problema de Exclusión Mutua
     Tenemos dos procesos 
     1. *Productor* que genera tareas
     2. *Consumidor* que consume las tareas

     *Observaciones:*
     + Recordemos que aparece el concepto de [[Condición de Carrera]] cuando
       dos o más *procesos* intentan acceder al mismo recurso,
       osea que tienen un recurso compartido, tanto para lectura/escritura
       (ej. una variable).
     + Ese recurso compartido entre los procesos que intentan modificar
       se conoce por [[Sección Crítica]] porque puede tener comportamientos inesperados
       (Ej. que varios incrementen su valor varias veces, y el resultado final sea otro)
     + El problema del resultado inesperado se debe a que NO están sincronizados,
       y según el *Planificador* puede hacer que uno se ejecute antes o después que el otro,
       que es el concepto de [[Velocidad Relativa]]
     + Con el uso de los *semáforos* evitamos esos problemas

     *Problema Actual:*
     El problema es que ambos leen/modifican un recurso compartido ~listaTareas~ 
     de forma *concurrente* y NO están sincronizados.
     Si los dos trabajan sobre un mismo recurso, este recurso se convierte en
     una *sección crítica*
     Además también puede suceder el concepto de [[Condición de Carrera]]

     *Solución:*
     Implementamos un ~Semáforo Mutex~ para que sólo uno de los procesos pueda leer ó modificar
     ese recurso ~listaTareas~, que NO puedan hacerlo ambos al mismo tiempo 
     y se vayan alternando.
    
     Este sería la implementación con problemas de [[Exclusión mutua]]

     #+BEGIN_SRC C
       // Proceso (1) - Consumidor
       while(1){
         tarea = obtenerTarea(listaTareas);

         ejecutarTarea(tarea);
       }


       // Proceso (2) - Productor
       while(1){
         nuevaTarea = crearTarea();

         agregarTarea(nuevaTarea, listaTareas);
       }
     #+END_SRC
     
     Este sería la implementación sin problemas de [[Exclusión mutua]]
     solo agregamos un *semáforo mutex*

     #+BEGIN_SRC C
       // Semáforo Mutex
       // - Lo inicializamos en 1 para que alguno de los procesos se active
       mutexLista = 1;

       // Proceso (1) - Consumidor
       // - Ahora tiene un "semaforo Mutex" para leer la listaTareas
       // solo si el proceso (2) NO lo está usando
       while(1){

         wait(mutexLista);                   // 1. pedimos el recurso (por si otro proceso lo usa)
         tarea = obtenerTarea(listaTareas); //  2. lo utilizamos (hacemos una lectura de los datos)
         signal(mutexLista);                //  3. lo liberamos (xq ya no lo usamos)

         ejecutarTarea(tarea);
       }


       // Proceso (2) - Productor
       while(1){
         nuevaTarea = crearTarea();

         wait(mutexLista);                    // 1. lo pedimos al recurso (por si otro proceso lo usa)
         agregarTarea(nuevaTarea, listaTareas);    // 2. lo utilizamos (agregamos datos)
         signal(mutexLista);                       // 3. lo liberamos (xq ya no lo usamos)
       }
     #+END_SRC
**** Ejemplo 2 - Semaforo Contador - Problema de Orden de ejecución
     Retomamos el ejemplo (1) que tenía problemas de *exclusión mutua*
     pero sigue teniendo problemas...

     *Problema actual:*
     + Un consumidor puede tratar de obtener tareas que aún no tiene disponibles.
     + Al pedir el recurso sin tareas disponibles, estamos bloqueando a los dos procesos
       - El consumidor trata de usar tareas que no tiene
       - El productor no puede agregar tareas porque el consumidor lo bloquea

     *Solución:*
     + Agregamos un [[Semáforo Contador]] para que el proceso *consumidor* lo utilice
        sólo si hay tareas pendientes
     + Este *semáforo contador* resuelve el problema del orden de ejecución

     *Observación:*
     Es importante el orden entre ~wait(tareasPendientes)~ y ~wait(mutexLista)~
     porque sino se van a bloquear entre ellos. 
     Si primero habilitamos el acceso al recurso con ~wait(mutexLista)~ entonces
     se va a quedar bloqueado tratando de usar tareas que NO tiene

     #+BEGIN_SRC C
       // Proceso (1) - Consumidor
       // Ahora tiene un "semaforo contador" para pedir tareas, solo si las hay

       // Semáforo Mutex
       // - Lo inicializamos en 1
       // para que alguno de los procesos se active, y se empiecen a alternando 
       mutexLista = 1;
       // Semáforo Contador
       // - lo inicializamos en 0,
       // para que el "consumidor" no trate de consumir tareas que no hay
       tareasPendientes = 0;

       while(1){
         // 1. "Semáforo Contador"
         // - preguntamos si hay tareas pendientes
         wait(tareasPendientes);
         // 2. "Semáforo Mutex"
         // - pedimos el recurso (por si otro proceso lo usa)
         wait(mutexLista);
         //  3. lo utilizamos (hacemos una lectura de los datos)
         tarea = obtenerTarea(listaTareas);
         //  4. lo liberamos (xq ya usamos lo que necesitabamos, guardamos los datos)
         signal(mutexLista);

         ejecutarTarea(tarea);
       }

       // Proceso (2) - Productor
       while(1){
         nuevaTarea = crearTarea();

         // 1. "Semáforo Mutex"
         // - pedimos al recurso (por si el otro proceso lo está usando)
         wait(mutexLista);
         // 2. lo utilizamos (agregamos datos)
         agregarTarea(nuevaTarea, listaTareas);
         // 3. "Semáforo Mutex"
         // - lo liberamos (xq ya no lo usamos, así lo usa el otro proceso)
         signal(mutexLista);
         // 4. "Semáforo Contador"
         // - liberamos el recurso (le avisamos al otro proceso que ya hay tareas cargadas)
         signal(tareasPendientes);
       }
     #+END_SRC
**** Ejemplo 3 - Semáforo Contador - Limitar Cantidad de Accesos
     En el ejemplo (2) teniamos problemas de que no podiamos limitar la cantidad de tareas

     *Problema actual:*
     - El productor puede generar infinita cantidad de tareas

     *Solución:*
     - Agregamos otro [[Semáforo Contador]] que para limitar la cantidad de accesos
       al recurso de ~listaTareas~

     *Observación:*
     + Recordemos que un *semáforo contador* se inicializa en N,
        y es la cantidad de procesos pendientes a ejecutar

     #+BEGIN_SRC C
       // Proceso (1) - Consumidor
       // - Ahora tiene un "semaforo contador" para pedir tareas, solo si las hay

       // Semáforo Mutex
       // - Lo inicializamos en 1
       // para que alguno de los procesos se active, y se empiecen a alternando
       mutexLista = 1;
       // Semáforo Contador (1)
       // - lo inicializamos en 0,
       // para que el "consumidor" no trate de consumir tareas que no hay
       tareasPendientes = 0;
       // Semaforo Contador (2)
       // - Lo inicializamos en 20,
       // para limitar la cantidad
       lugarEnLista = 20;

       while(1){
         // 1. "Semáforo Contador"
         // - preguntamos si hay tareas pendientes
         wait(tareasPendientes);
         // 2. "Semáforo Mutex"
         // - pedimos el recurso (por si otro proceso lo usa)
         wait(mutexLista);
         //  3. lo utilizamos (hacemos una lectura de los datos)
         tarea = obtenerTarea(listaTareas);
         //  4. lo liberamos (xq ya usamos lo que necesitabamos, guardamos los datos)
         signal(mutexLista);
         // 5. Avisamos que ya consumimos una tarea, que hay una menos
         // para que el "Productor" pueda agregar nuevas
         signal(lugarEnLista);

         ejecutarTarea(tarea);
       }

       // Proceso (2) - Productor
       while(1){
         nuevaTarea = crearTarea();

         // 1. "Semáforo Contador" (1)
         // - limitamos la cantidad de accesos
         wait(lugarEnLista);
         // 2. "Semáforo Mutex"
         // - pedimos al recurso (por si el otro proceso lo está usando)
         wait(mutexLista);
         // 3. lo utilizamos (agregamos datos)
         agregarTarea(nuevaTarea, listaTareas);
         // 4. "Semáforo Mutex"
         // - lo liberamos (xq ya no lo usamos, así lo usa el otro proceso)
         signal(mutexLista);
         // 5. "Semáforo Contador" (2)
         // - liberamos el recurso (le avisamos al otro proceso que ya hay tareas cargadas)
         // - Es otro semaforo contador, no confundir con el que usa el recurso lugarEnLista
         signal(tareasPendientes);
       }
     #+END_SRC
**** Ejemplos 1-2-3
     En este ejemplo es *IMPORTANTE* el orden de los ~wait()~ en *CONSUMIDOR*es decir
     1. ~wait(tareasPendientes)~ (espera que hayan tareas, para utilizar el recurso)
     2. ~wait(mutexLista)~ (como está inicializado en 1, el proceso se va a bloquear
     y usará el recurso)
    
     Si lo hacemos al revés, se van a BLOQUEAR entre ellos, porque
     1. Si primero hiciera ~wait(mutexLista)~ el proceso *CONSUMIDOR*
        se bloquearia, tratando de usar el recurso de ~listaTareas~ que está vacío,
     2. y el proceso *PRODUCTOR* trataría de acceder al recurso ~listaTareas~
        esperando con ~wait(mutexLista)~ pero NO podría, porque está siendo
        bloqueado por el *CONSUMIDOR*

     *Observación:*
     _Solo UNO DE LOS PROCESOS puede usar el recurso_ en un instante
     de tiempo, ambos a la vez NO PUEDEN ..!
 
     #+BEGIN_SRC C
       mutexLista = 1; // lo inicializamos

       // lo ira incrementando por el productor (con nuevas tareas)
       // y decrementando por el consumidor (mientras las utiliza)
       tareasPendientes = 0;

       lugarEnLista = 20;

       // Proceso (1) - CONSUMIDOR
       //
       // Obs: Es importante el orden 1) tareasPendientes 2) mutexLista,
       // xq si es al revés sen van a bloquear entre ellos.
       while(1){
         // 1. tareasPendientes
         // - el consumidor puede esperar, quedarse bloqueado
         // hasta que generen más tareas
         // - para evitar que no obtenga una tarea de una lista vacia
         wait(tareasPendientes);

         // 2. mutexLista
         // - verificar si la lista disponible, si otro no lo está usando
         // - por si aparece el concepto de "condición de carrera"
         wait(mutexLista);

         // 3. usamos el recurso (lectura de los datos)
         tarea = obtenerTarea(listaTareas);

         // 4. liberamos el recurso
         // - NO importa el orden de los signal
         signal(mutexLista);
         signal(lugarEnLista)

         ejecutarTarea(tarea);
       }


       // Proceso (2) - PRODUCTOR
       //
       while(1){
         nuevaTarea = crearTarea();

         // 1. lugarEnLista:
         // - podriamos limitar la cantidad de tareas
         // - el producto se bloquearía, hasta que se liberen
         //   (por el consumidor) las tareas
         // usariamos un semaforo contador
         wait(lugaEnLista);

         // 2. mutexLista
         // - verificar si la lista disponible, si otro no lo está usando
         // - por si aparece el concepto de "condición de carrera"
         wait(mutexLista);

         // 3. Usamos el recurso "listaTareas"
         agregarTarea(nuevaTarea, listaTareas);

         // 4. liberamos el recurso
         // - NO importa el orden de los signal

         // liberamos el recurso, porque ya NO lo necesitamos
         signal(mutexLista);
         // libera cada tarea
         signal(tareasPendientes);
        }
     #+END_SRC
**** Ejemplo - 4
     NO puede haber mas de un proceso utilizando el buffer

     #+BEGIN_SRC C
       Productor(){
         X=producir();

         wait(s_buffer);
         agregar(X, buffer);
         signal(s_buffer);
       }

       Consumidor(){
         wait(s_buffer);
         Y=extraer(X, buffer);
         signal(s_buffer);

         consumir(Y);
       }
     #+END_SRC
** [DONE] Inversión de prioridades
   CLOSED: [2021-09-26 dom 23:14]
   + Si un proceso con baja prioridad ocupa la CPU => se desaloja si aparece otro con más prioridad
   + Utilizando *planificadores* con prioridad, para _desalojar procesos menos prioritarios_
   + Evita que un *proceso* con baja prioridad tome el control de un *semaforo mutex*
     (si uno con menor prioridad lo está usando, el SO lo desaloja, si otro de mayor prioridad lo necesita) 

   #+BEGIN_COMMENT
   <<DUDA>>:
   cada proceso que ingresa tiene misma prioridad, y luego según el tipo de proceso que caiga en ready
   se sube/baja prioridad?

   verificar con los gantt
   #+END_COMMENT
** [DONE] Monitores
   CLOSED: [2021-09-26 dom 22:35]
   + Solo UN proceso/hilo puede estar activo en el monitor
   + Es un mecanismo que ofrece [[Mutua exclusión]] 
     (para evitar el concepto de [[Condición de Carrera]] )
  
   *Ventajas:*
   - No accedemos a la variable (sección crítica),
   - Invocamos una función para ese recurso compartido
   - encapsula la lógica, evitando agregar a cada rato el ~wait()~ y ~signal()~
     
