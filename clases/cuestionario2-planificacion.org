#+STARTUP: inlineimages
#+BEGIN_COMMENT
Reforzar las métricas Ej. tiempo de espera, ...
#+END_COMMENT
* Cuestionario (1)
** [#A] Pregunta (1)
   #+BEGIN_QUOTE
   V/F
   ¿En caso de utilizar jacketing sería lo mismo utilizar ULTs/KLTs?
   #+END_QUOTE

   #+BEGIN_COMMENT
   FALSO.
   Jacketing es una técnica para que los KLT ó Procesos asociados a los ULTs, no se bloqueen.

   Convierte las llamadas a syscalls de los ULTS de syscalls "bloqueantes" a "no bloqueantes",
   ya que usan wrappers de la biblioteca de ULTs,
   permitiendo que la biblioteca pueda replanificar y elija otro ULT que esté en READY

   Ej. Si un KLT tiene 2 ULTs + jacketing, y uno de esos hace una llamada a una I/O => el KLT elegirá otro proceso
   #+END_COMMENT

   #+BEGIN_COMMENT
   NO confundir "jacketing" con si el enunciado dice "las E/S son wrapeadas por la biblioteca",
   - si se usa jacketing
     1) el KLT o Proceso seguirá ejecutando sus ULTs mientras tenga ULTs para elegir
     2) Si uno de los ULTs hace una I/O pero hay otro UTL en ready para elegir => el proceso ó KLT no se bloquea, sigue ejecutando porque elije ese otro ULT
   - si las "E/S son wrapeadas por la biblioteca" + sin jacketing
     1) la biblioteca de ULTs podrá guardar el contexto y cuando el KLT ó Proceso sea elegido nuevamente, ésta sabrá que ULT elegir porque puede replanificar
     2) si uno de los ULTs hace una I/O el proceso ó KLT se bloqueará, pero cuando ese proceso ó KLT sea elegido nuevamente => la biblioteca de ULTs sabrá cual ULT elegir
   #+END_COMMENT
*** Respuesta Correcta
    F
*** Justificación Respuestas Incorrectas
*** Observaciones
   #+BEGIN_QUOTE
    Ya que el SO sigue sin "ver" dichos ULTs no puede planificarlos
    (ej, asignarles un Q, o ejecutarlos en distintas CPUs)
    
    Recordar que lo único que soluciona jacketing es que el KLT/Proceso asociado a los ULTs no se bloquee
    y la biblioteca pueda planificar otro ULT en caso de tener alguno LISTo.
   #+END_QUOTE
** Pregunta (2)
   #+BEGIN_QUOTE
   Indique cuáles de las siguientes afirmaciones son VERDADERAs sobre planificación con biblioteca de ULTs
   
   1. Si hay varios KLTs con ULTs todos los KLTs deben usar la misma *biblioteca de ULTs*
   2. Si decidimos usar ULTs es igual de útil usar directo ~syscalls~ (/ej. write/) que usar los *wrappers* de las ~sycalls~ provistas por la biblioteca
   3. Cuando un ULT necesita realizar una IO se lo pide al SO con una ~syscall~. En este caso, el SO puede diferenciar cuál ULT lo está pidiendo.
   4. Todas son correctas
   5. Ninguna es correcta
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 1) FALSO, cada KLT puede usar una biblioteca de ULTs diferente
   - 2) FALSO, si los ULTs llaman directamente a las syscalls el proceso ó KLT se bloqueará y la biblioteca de ULTs no llegará a guardar el contexto,
        por tanto cuando el KLT ó proceso que contiene esos ULTs vuelva a ser elegido, la biblioteca de ULTs seguirá ejecutando el último ULT que estaba ejecutando
        cuando el proceso se bloqueó..
        En cambio si los ULTs usan Wrappers de las syscalls provistas por la biblioteca, la biblioteca tendrá tiempo para guardar el contexto,
        y cuando el proceso ó KLT que contiene a esos ULTs vuelva a ser elegido, la biblioteca de ULTs elegirá según el algoritmo de planificación elegido
   - 3) FALSO, el SO no conoce a los ULTs, sólo a los Procesos y a los KLTs
   - 5) Verdadero
   #+END_COMMENT
*** Respuesta Correcta
   - 5) Ninguna es correcta
*** Justificación Respuestas Incorrectas
*** Observaciones
    Son todas falsas:
    - Cada KLT puede usar una biblioteca distinta, y por ende tener distintos criterios de planificación
    - Si llamamos directo a syscalls bloqueantes desde el código de nuestros ULTs no permitimos que la biblioteca replanifique cuando sea necesario para el algoritmo usado
    - El SO no "ve" ni sabe de la existencia de los ULTs, cuando le llega el pedido de una sycall, sólamente sabe que vino de una entidad de planificación que conoce, como un KLT o un proceso
** [#A] Pregunta (3)
   #+BEGIN_QUOTE
   Un proceso posee 3 KLTs y cada uno 3 ULTs asociados.
   Si un ULT necesita hacer una ~syscall bloqueante~ (ej read) ...
   ¿cuáles de las siguientes afirmaciones PODRÍAN ser ciertas?

   1. Por default todo el KLT se bloquea
   2. Por default todo el KLT y el proceso asociado se bloquean
   3. Podría no bloquearse todo el KLT
   4. Al finalizar la *operación bloqueante* y ser seleccionados por el planificador del SO vuelve a ejecutar el mismo ULT
   5. Al finalizar la *operación bloqueante* y ser seleccionados por el planificador del SO ejecuta el ULT que seleccione la biblioteca de ULTs
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 1) V
   - 2) V
   - 3)* V -> (/si la biblioteca de ULTs del KLT utiliza "Jacketing" => podría no bloquearse el KLT, y ejecutar otro ULT que esté en ready/)
   - 4) V
   - 5)* V -> (/si los ULTs hacen las I/O a través wrappers de la Biblioteca de ULTs => la biblioteca de ULTs podría guardar el contexto, y cuando el KLT que contiene a eso ULTs sea elegido para ejecutar, la biblioteca podrá replanificar/)
   #+END_COMMENT
*** Respuesta Correcta
    Todas
*** Justificación Respuestas Incorrectas
*** Observaciones
   #+BEGIN_QUOTE
    El SO por default "ve" que la syscall llega del KLT asociado, por lo que lo bloquea.
    Por otro lado, en caso de utilizar *Jacketing* => podría ejecutar otro ULT (/si hubiera alguno en ready/) del mismo KLT sin bloquearse.
    
    Luego de finalizar la *operación bloqueante*:
    - Si se llamó directamente a la ~syscall~ (osea sin wrappers la biblioteca) => va a continuar con el último ULT que hizo la llamada a la syscall
    - Si se realizó la _syscall desde una función wrapper de la biblioteca_ => la bilioteca podrá seleccionar al mismo u otro ULT a ejecutar según el algoritmo
      (que igualmente podría ser el que originó la llamada)
    - _En caso de que justo el último KLT de un proceso se bloquee, quedaría todo el proceso en estado bloqueado_
   #+END_QUOTE

   #+BEGIN_COMMENT
   <<DUDA>>:
   Tengo mis dudas con la última observación
   #+END_COMMENT
** [#A] Pregunta (4)
   #+BEGIN_QUOTE
   V o F.
   En caso de elegir usar _ULTs con Jacketing_ vs KLTs, la única desventaja sería no poder aprovechar el *multiprocesamiento*
   #+END_QUOTE

   #+BEGIN_COMMENT
   FALSO.
   El multiprocesamiento se refiere a la ejecución con "multiples procesadores",
   poder ejecutar múltiples procesos en paralelo osea en simultaneo...

   Por tanto si un proceso monopoliza un CPU porque el KLT ó el Proceso usa una biblioteca de ULTs con jacketing,
   tendriamos los demás procesadores
   #+END_COMMENT
*** Respuesta Correcta
    Falso
*** Justificación Respuestas Incorrectas
*** Observaciones
   #+BEGIN_QUOTE
   Otra desventaja es que en caso de tener un algoritmo con quantum,
   todos los ULTs deberán compartirlo vs en un esquema con KLTs cada uno recibiría 1 Q
   #+END_QUOTE

   #+BEGIN_COMMENT
   <<DUDA>>
   No entendi la relación entre la observación y la pregunta dada.
   #+END_COMMENT
** [#A] Pregunta (5)
   #+BEGIN_QUOTE
   Considere el siguiente sistema en el que en un momento (está empezada la ejecución) tenemos el siguiente estado.
   Sabiendo que el SO planifica con SJF, que el estimado anterior de KAA fue 3 y que los 3 ULTs ya estaban ready.
   Responda cuáles de las siguientes afirmaciones son verdaderas. (aclaración alpha = 0,5)
   Fórmula SJF: ~proxima_estimacion = rafaga_real_anterior*alfa + (1-alfa)*anterior_estimacion~

   1. El próximo estimado de KAA será 4
   2. KAA nunca llega a bloquearse
   3. KAA utiliza una biblioteca de ULTs con jacketing
   4. La biblioteca de ULTs de KAA utiliza SJF
   #+END_QUOTE

   #+BEGIN_COMMENT
   prox_est(kaa)= 5*0.5 + (1-0.5)*3 = 2.5 + 1.5 = 4 <-- ojo! porque pregunta por el KLT, no por uno de los ULTs

   - 1)* Verdadero, el próximo estimado sería de 4
   - 2) FALSO, no se sabe si luego puede seguir ejecutando
   - 3) Verdadero, porque luego de cada syscall bloqueante de uno de sus ULTs (ej. IO) el KLT no se bloquea, y sigue ejecutando otro ULT
   - 4) FALSO, si usara SJF entonces el ULT UAA3 hubiera sido el primero en ejecutar al tener la menor ráfaga
   #+END_COMMENT

   [[./img/gantt-naty1.png]]
*** Respuesta Correcta
    - 1) El próximo estimado de KAA será 4
    - 3) KAA utiliza una biblioteca de ULTs con jacketing
*** Justificación Respuestas Incorrectas
*** Observaciones
    - Como el estimado anterior fue de 3, y ejecutó 5 unidades hasta bloquearse (entre todos los ults) su próximo estimado es de (3+5)/2
    - Hay un momento en el que todos los ULTs están bloqueados, por lo que el KLT se bloquea (la biblioteca no tiene nada más para ejecutar)
    - La biblioteca de KAA usa jacketing ya que vemos que hay un ULT ejecutando mientras otro realiza una IO
    - No podemos afirmar que la biblioteca de KAA utilice SJF ya que depende un poco de los estimados, bien podría ser FIFO
* [WAITING] Cuestionario (2)
** [#B] Pregunta (1)
   #+BEGIN_QUOTE
   ¿Cuál es el planificador que es más importante que tenga menos *overhead*?

   1. El encargado de *admitir nuevos procesos* al sistema (PLP)
   2. El encargado de *hacer swapping* (PMP)
   3. El encargado de *poner procesos en ejecución* (PCP)
   #+END_QUOTE

   #+BEGIN_COMMENT
   El (PCP) Planificador de Corto plazo, el que pone los procesos en ejecución..
   porque es el que más seguido se va a ejecutar.
   #+END_COMMENT
*** Respuesta Correcta
   - (3) El encargado de poner procesos en ejecución (PCP)
*** Justificación Respuestas Incorrectas
*** Observaciones
    El *Planificador de corto plazo*, el encargado de _seleccionar procesos para ejecutar_,
    es el que _va a ejecutarse muy seguido_ por lo que es necesario que tome buenas decisiones
    y que tenga el menor overhead posible.
** Pregunta (2)
   #+BEGIN_QUOTE
   ¿Qué es el *tiempo de espera*?
   
   1. El tiempo en el que el _proceso está en la cola de bloqueado_
   2. El tiempo en el que el _proceso no está en ejecución_
   3. El tiempo en el que el _proceso está en la cola de listos_
   4. El tiempo en el que el _proceso está en suspendido_
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 3. El tiempo en el que el _proceso está en la cola de listos_
   #+END_COMMENT
*** Respuesta Correcta
   - (3) El tiempo en el que el proceso está en la cola de listos
*** Justificación Respuestas Incorrectas
*** Observaciones
   #+BEGIN_QUOTE
    El *tiempo de espera*, es el _tiempo en el que le negamos CPU al proceso_,
    podríamos haberlo elegido para ejecutar, pero el planificador seleccionó a otro.
   #+END_QUOTE
** [WAITING] [#A] Pregunta (3)
   #+BEGIN_QUOTE
   ¿Cuál/es de las siguientes afirmaciones son "falsas" sobre FIFO?
   
   1. Podría permitir que un proceso _monopolice la CPU_
   2. Podría ser útil para _correr procesos secuenciales_
   3. Minimiza los *cambios de contexto*
   4. Todas
   5. Ninguna
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 1) Verdadero
   - 2) Verdadero
   - 3) *Verdadero
   #+END_COMMENT

   #+BEGIN_COMMENT
   <<DUDA>>:
   Aunque.. para mi ese (3) depende de las ráfagas de CPU de los procesos..
   porque se ejecutaría 1,2,1,2,1,2,1,2,1,2 y habrían muchos cambios de contextos,
   al haber varios switch process
   #+END_COMMENT
*** Respuesta Correcta
   1. Ninguna
*** Justificación Respuestas Incorrectas
*** Observaciones
   #+BEGIN_QUOTE
    Al no tener desalojo, se espera a que el proceso voluntariamente libere la CPU,
    esto potencialmente podría generar que un proceso nunca la libere.
    
    En un contexto en el que se quiere correr un lote de procesos en forma *batch*
    minimizando el overhead, es una buena opción.
    
    _Al ejecutar un proceso después del otro, minimiza la replanificación y por ende los cambios de contexto._
    #+END_QUOTE
** [WAITING] [#A] Pregunta (4)
   #+BEGIN_QUOTE
   Indique cuál de las siguientes afirmaciones son correctas sobre *SJF*
   
   1. Puede implementarse con o sin desalojo
   2. Minimiza el *tiempo de espera promedio*
   3. Para poder optimizarlo se puede utilizar la *media exponencial*
   4. Prioriza a los procesos *CPU Bound*
   5. Es un algoritmo con poco *overhead*
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 1) Verdadero
   - 2)* Verdadero
   - 3)* Falso, -> la *media exponencial* sirve para estimar las ráfagas (???)
   - 4)* Falso
   - 5)* Falso, -> el cálculo de la *media exponencial* produce el overhead
   #+END_COMMENT
*** Respuesta Correcta
   - 1) Puede implementarse con o sin desalojo
   - 2) Minimiza el tiempo de espera promedio
*** Justificación Respuestas Incorrectas
*** [WAITING] Observaciones
   #+BEGIN_QUOTE
    La *media exponencial* es necesaria para poder implementarlo ya que uno
    no podría predecir las siguientes ráfagas, sólo puede estimarlas.
    
    _Prioriza a los procesos IO Bound_ (?)
    
    Tiene bastante *overhead* por el *cálculo de la media exponencial*
    y aún más overhead si es con desalojo porque el SO interviene a cada rato
   #+END_QUOTE
    
    #+BEGIN_COMMENT
    <<DUDA>>:
    puede ser que me haya equivocado con lo de io-bound? no es cpu-bound?
    
    el hrrn es el que prioriza io-bound, porque a mayor tiempo de espera => mas prioridad tiene
    #+END_COMMENT    
** [#A] Pregunta (5)
   #+BEGIN_QUOTE
   V o F . HRRN podría implementarse con o sin desalojo según cómo se prefiera
   #+END_QUOTE

   #+BEGIN_COMMENT
   FALSO.
   El HRRN es sin desalojo, si se considerara HRRN con desalojo generaría mucho overhead,
   porque como en el cálculo considera el "tiempo de espera" (waiting time) => replanificaría en cada instante
   #+END_COMMENT
*** Respuesta Correcta
    Falso
*** Justificación Respuestas Incorrectas
*** Observaciones
    Como tiene en cuenta la variable "tiempo de espera", en caso de implementarlo
    con desalojo habría que estar replanificando con cada instante que pasa,
    generando demasiado overhead.
** [#A] Pregunta (6)
   #+BEGIN_QUOTE
   V o F. En RR el SO lanza una *interrupción* para desalojar al proceso en ejecución
   y selecciona al siguiente proceso en READY
   #+END_QUOTE

   #+BEGIN_COMMENT
   FALSO!!!!
   El SO no lanza la interrupcion de clock, ésta es a nivel de hardware, el SO sólo la atiende
   #+END_COMMENT
*** Respuesta Correcta
    Falso
*** Justificación Respuestas Incorrectas
    En RR, _el SO no lanza la *interrupción de clock*_, sino que atiende la *interrupción de clock*
*** Observaciones
    No es el SO el que interrumpe la ejecución sino el timer (que es programado por el
    planificador antes de poner a ejecutar el proceso de usuario) lanzando una interrupción
    de fin de quantum. Luego el SO atiende dicha interrupción y el planificador
    selecciona a otro proceso para ejecutar.
** [#B] Pregunta (7)
   #+BEGIN_QUOTE
   V o F. Para un *algoritmo de tipo "Feedback"* no es suficiente saber que tiene dos
   colas de planificación y que ambas utilizan RR para poder implementar el algoritmo.
   #+END_QUOTE

   #+BEGIN_COMMENT
   Verdadero...
   #+END_COMMENT
*** Respuesta Correcta
    Verdadero
*** Justificación Respuestas Incorrectas
*** Observaciones
    Para el *algoritmo de tipo Feedback* es necesario saber también:
    - a qué cola ingresan los procesos nuevos?
    - cuáles son las prioridades entre colas?
    - hay desalojo entre ellas?
    - cuál es el criterio para pasar de una cola de mayor prioridad?
    - se puede pasar de una cola de menor prioridad a una de mayor?
** [#A] Pregunta (8)
   #+BEGIN_QUOTE
   ¿Cuáles de los siguientes algoritmos podrían sufrir de inanición?
   
   1. FIFO <- Ojo..!
   2. SJF
   3. Por prioridades
   4. RR
   5. VRR
   6. HRRN
   7. Feedback
   #+END_QUOTE
*** Respuesta Correcta
   - (2) SJF
   - (3) Por prioridades
   - (7) Feedback (/porque depende de los algoritmos elegidos/)
*** Justificación Respuestas Incorrectas
    _Todos los de sin desalojo que priorizen, podria generar starvation_
*** Observaciones
    1. FIFO: respeta el orden de llegada, por lo que atenderá a todos en dicho orden
    2. RR: igual que FIFO, pero con límite de Q
    3. VRR: podría generar la impresión de generar inanición por la cola prioritaria.
       Sin embargo, lo que hay que recordar es que ese Q' tiende a 0, es decir,
       cuando finalmente consuma todo el Q inicial vuelve a la cola menos prioritaria.
    4. HRRN: fuera de que privilegia a los procesos de ráfagas cortas, al meter en la
       ecuación el tiempo de espera hace que los procesos largos no sufran de inanición
* Cuestionario (3)
** [#A] Pregunta (1)
   #+BEGIN_QUOTE
   Los *planificadores de largo y mediano plazo* pueden afectar el orden de los procesos
   
   a. En la lista de procesos suspendidos. (SUSPEND)
   b. En lista de procesos listos para ejecutar. (READY)
   c. En la lista de procesos nuevos. (NEW)
   #+END_QUOTE
*** Respuesta correcta
   - b) En lista de procesos listos para ejecutar.
*** Observaciones
    - El *planificador de largo plazo*, al momento de admitir un proceso nuevo, 
      puede afectar el orden de los procesos de Listos.
    - El *planificador de medio plazo*, puede afectar el orden de los procesos listos 
      cuando un proceso es pasado de disco a memoria.
** [#B] Pregunta (2)
   #+BEGIN_QUOTE
   El *planificador de corto plazo* es invocado cuando
   
   a. Se realiza una llamada al sistema o una interrupción. 
   b. Se realiza una llamada al sistema y una interrupción.
   c. Ninguna de las anteriores.
   #+END_QUOTE
*** Respuesta correcta
   a. Se realiza una llamada al sistema o una interrupción. 
*** Observaciones
    - Cuando un proceso realiza una *llamada al sistema*, podría cambiar su estado a *Bloqueado*.
    - Una *interrupción* puede provocar que
      - que un proceso se desbloquee (Ej. Int. por fin de IO) y quede en *estado Listo*
      - ó que un proceso cambie de estado *Ejecutando a Listo*. (Ej. Int. de Clock)
** Pregunta (3)
   #+BEGIN_QUOTE
   El *Response Time* es un criterio de planificación
   
   a. Ninguna de las anteriores.
   b. Orientado al sistema.
   c. Orientado al usuario. 
   #+END_QUOTE
*** Respuesta correcta
   c. Orientado al usuario. 
*** Observaciones
    Es el tiempo que el usuario espera desde que realiza una operación hasta recibe alguna respuesta del sistema.
** Pregunta (4)
   #+BEGIN_QUOTE
   Al utilizar el *algoritmo Round Robin* (RR), el quantum
   
   a. Ninguna de las anteriores. 
   b. Debería ser lo más grande posible.
   c. Debería ser lo más chico posible.
   #+END_QUOTE
*** Respuesta correcta
   a. Ninguna de las anteriores. 
*** Observaciones
    - Si el *quantum es muy grande*, el algoritmo degenera en FIFO.
    - Si el *quantum es muy chico*, el algoritmo se vuelve más justo porque los procesos avanzan 
    de manera más pareja, pero genera mucho *Overhead* por todas las intervenciones necesarias del sistema operativo.
** [#A] Pregunta (5)
   #+BEGIN_QUOTE
   La *Interrupción de Clock* permite
   
   a. Que el procesador realice un *cambio de proceso* (switch process)
   b. Ninguna de las anteriores.
   c. Que un proceso pueda realizar una *llamada al sistema*
   #+END_QUOTE
*** Respuesta correcta
   b. Ninguna de las anteriores.
*** Observaciones
   #+BEGIN_QUOTE
    La *interrupción de Clock* permite que el SO, tome el control del procesador 
    para que realice alguna tarea. Esa tarea puede ser el realizar un cambio de proceso, o no.
    
    *El procesador no realiza cambios de proceso*
   #+END_QUOTE
** [TODO] Pregunta (6)
   #+BEGIN_QUOTE
   Para algoritmos que usan la próxima ráfaga de CPU, como el SJF
   
   a. Generalmente solo se pueden implementar con un estimador de ráfagas.
   b. Generalmente se pueden implementar «de una», porque los procesos proveen esa información.
   c. Ninguna de las anteriores. 
   #+END_QUOTE
*** Respuesta correcta
   a. Generalmente solo se pueden implementar con un estimador de ráfagas.
*** Observaciones
   #+BEGIN_QUOTE
   El SO no conoce de antemano cuál será el tiempo de cada ráfaga.
   Por lo tanto es necesario estimarla.
   #+END_QUOTE
** [#A] Pregunta (7)
   #+BEGIN_QUOTE
   *Starvation* (inanición) es una problemática que
   
   a. Ocurrirá siempre que se utilizen algoritmos como SJF.
   b. Ninguna de las anteriores. 
   c. Podría nunca ocurrir, independientemente del algoritmo utilizado.
   #+END_QUOTE
*** Respuesta correcta
   c. Podría nunca ocurrir, independientemente del algoritmo utilizado.
*** Observaciones
    Algunos algoritmos no sufren inanición. Otros algoritmos PODRÍAN sufrirla, 
    pero tienen que darse ciertas condiciones. 
    Por ejemplo SJF puede sufrir inanición, pero si todas las ráfagas de 
    los procesos son iguales, entonces no habrá inanición.
** Pregunta (8)
   #+BEGIN_QUOTE
   En un *algoritmo multinivel realimentado* (Feedback Multinivel)
   
   a. La prioridad de los procesos es estática.
   b. Ninguna de las anteriores.
   c. La prioridad de los procesos es dinámica. 
   #+END_QUOTE
*** Respuesta correcta
   c. La prioridad de los procesos es dinámica. 
*** Observaciones
   #+BEGIN_QUOTE
   Cuando se utiliza "feedback multinivel", durante el ciclo de vida de un proceso, 
   este puede moverse entre las diferentes colas de "ready" que pueden tener 
   diferentes prioridades entre sí.
   
   El sistema operativo seleccionará los procesos de la cola más prioritaria. 
   En caso que esta última cola esté vacía, se continúa por la siguiente en orden de prioridad.
   #+END_QUOTE
** [#B] Pregunta (9)
   #+BEGIN_QUOTE
   En un SO con RR y *procesos CPU-Bound* y *I/O-Bound* se verían perjudicados
   
   a. Ninguna de las anteriores.
   b. Los procesos CPU Bound.
   c. Los procesos I/O Bound. 
   #+END_QUOTE
*** Respuesta correcta
   c. Los procesos I/O Bound. 
*** Observaciones
   #+BEGIN_QUOTE
    Los I/O Bound (o Limitados por E/S) serán perjudicados porque sus ráfagas de CPU son cortas.
    Por lo tanto, no suelen aprovechar todo el quantum asignado.
    
    Además estarán compitiendo por el uso del procesador, con otros procesos que podrían estar 
    aprovechando más tiempo el procesador. Para atenuar este problema está el algoritmo Virtual Round Robin.
   #+END_QUOTE
* [WAITING] Cuestionario (5)
** [#A] Pregunta 1
   #+BEGIN_QUOTE
   En que momento se atienden las interrupciones?
   (Suponiendo que NO están deshabilitadas)
   #+END_QUOTE
*** Respuesta Correcta
   Luego de finalizar el atender la instrucción en curso
** [WAITING] Pregunta 2
   #+BEGIN_QUOTE
   Cual seria la info básica que siempre se debe guardar
   antes de atender una interrupción?
   #+END_QUOTE
*** Respuesta Correcta
   #+BEGIN_QUOTE
   El (PC, Program Counter) porque guarda la dirección de memoria
   de la siguiente instrucción a ejecutar, para continuar el 
   ciclo de la instrucción

   y el (PSW, Program Status Word) porque guarda el bit que
   representa el modo (usuario/kernel)
   #+END_QUOTE

   #+BEGIN_COMMENT
   <<DUDA>>:
   El PSW guardaria en que modo estaba (usuario/kernel) para cuando
   se restaure el contexto, sepa si estaba en modo usuario o modo kernel
   para saber como ejecutar la siguiente instrucción a la que apunta el Program Counter?
   #+END_COMMENT
** Pregunta 3
   #+BEGIN_QUOTE
   ~CLI~ es una instrucción que lo que hace es deshabilitar las
   interrupciones. ¿Qué debería ocurrir si se ejecuta la misma?
   #+END_QUOTE
*** Respuesta Correcta
   #+BEGIN_QUOTE
   Depende de en que *modo de ejecución* se ejecute,

   Si estaba en Modo Usuario, _lanzaría una excepción_
   Si estaba en Modo Kernel, cambiaria el bit del *Interrupt Flag* del PSW e _iba a poder ejecutar_
   #+END_QUOTE
** Pregunta 4
   #+BEGIN_QUOTE
   Cual de las sig. son interrupciones sincrónicas?
   
   1) Acceder a una dirección de memoria NO permitida
   2) FIN de quantum
   3) FIN de entrada salida
   4) División por cero
   5) Error de un dispositivo
   6) *Llamado explícito a lanzar una interrupción
   #+END_QUOTE
   
   *Observación:*
   - Una ~interrupción sincrónica~ es el resultado de la ejecución de la CPU en ese momento
*** Respuesta Correcta
   #+BEGIN_QUOTE
   Las opciones 1) 4) 6) son Sincrónicas
   
   Las otras 2) 3) 5) son asíncronas
   #+END_QUOTE
** Pregunta 5
   #+BEGIN_QUOTE
   Cuales son las ventajas de los *microkernels*?
   
   1) Robustez, flexibilidad, tolerencia a fallas
   2) Facilidad de intercambiar un módulo con otro
   3) Es el más utilizado
   4) Buena comunicación entre módulos
   #+END_QUOTE
*** Respuesta Correcta
   - Robustez, flexibilidad, tolerencia a fallas
   - Facilidad de intercambiar un módulo con otro
*** Respuesta Incorrectas
   - Es el más utilizado (/el más utilizado es el monolítico/)
   - Buena comunicación entre módulos (/porque el paso de mensajes es a través de syscalls, y el kernel es el nexo entre los módulos/)
** Pregunta 6
   #+BEGIN_QUOTE
   Cual sería la forma correcta de acceder a un dispositivo desde un
   proceso de usuario? (Ej. leer de disco)
   
   1) Llamar a una función wraper que luego llama a una syscall
   2) Llamar a la syscall por el SO
   3) Llamar a una instrucció para realizar la IO
   4) Lanzar una interrupción para lograr un modo kernel, y luego la instrucción requerida
   #+END_QUOTE
*** Respuesta Correcta
   - Llamar a una función wraper que luego llama a una syscall
   - Llamar directamente a la syscall por el SO
*** Respuesta Incorrectas
   1. Llamar a una instrucción para realizar la IO
   2. Lanzar una interrupción para lograr un modo kernel, y luego la instrucción requerida
** Pregunta 7
   #+BEGIN_QUOTE
   Cuales de las siguientes afirmaciones son correctas?
   
   1. SI ocurre un *cambio de proceso* => va ocurrir mas de un *cambio de modo*
   2. SI ocurre un *cambio de contexto* => va a ocurir un *cambio de proceso*
   3. SI ocurre un *cambio de modo* => va a ocurrir un *cambio de contexto*
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 1) Verdadero, porque ModoUsuario->ModoKernel para guardar el contexto de ese proceso, y restaurar el otro, ModoKernel->ModoUsuario para retomar
   - 2) FALSO, puede estar ejecutando un proceso y de repente el SO atender una Interrupción, por tanto deba guardar el contexto, luego lo restaura y continua con el mismo proceso
   - 3) Verdadero, se debe guardar el contexto
   #+END_COMMENT
*** Respuesta Correcta
   - La 1) 
   - La 3)
*** Respuesta Incorrectas
   - la 2) porque puede haber una ~interrupcion~ y sigue ejecutando el mismo proceso ó también si hubo una ~syscall~
** [WAITING] Pregunta 8
   #+BEGIN_QUOTE
   Cuales de las sig. afirmaciones sobre procesos son FALSAS?
   
   1. Al finalizar se liberan los recursos que tenia asignados
   2. Por default comparten memoria con su proceso padre para poder comunicarse
   3. Posee un PCB que SIEMPRE debe esta en la RAM
   4. Son menos estables y seguros que los hilos KLTs
   5. Es la minima unidad de planificación para el SO
   6. Pueden comunicarse con otros procesos con otros procesos con paso de mensajes
   #+END_QUOTE

   #+BEGIN_COMMENT
   - 1) Verdadero
   - 2) Falso, es una de las técnicas, pero no por default
   - 3) Verdadero, para que el SO pueda administrar el proceso está en Disco ó Memoria
   - 4) Falso, son más seguros q los hilos porque estos comparten información
   - 5) Falso, los hilos son la menor unidad de planificación para el SO
   - 6) *Falso
   #+END_COMMENT

   #+BEGIN_COMMENT
   <<DUDA>>:
   Porque la (6) es falsa?, no se podían comunicar mediante "Paso de mensajes" ó "Memoria compartida"?
   #+END_COMMENT
*** Respuesta Correcta 
   - 2) solo comparten 
   - 4)
   - 5) suponiendo que el sistema soporte hilos
   - 6)
*** Respuesta Incorrectas
   - 1) 
   - la 3) porque si NO estuviera en RAM, y el proceso estuviese suspendido, osea está en disco, NO podriamos despertarlo
** [#B] Pregunta 9
   #+BEGIN_QUOTE
   Tanto los procesos como los KLTs y ULTs son creados a través de ~syscalls~
   brindadas por el SO. Es V/F?
   #+END_QUOTE

   #+BEGIN_COMMENT
   Falso, sólo los procesos son creados a través de syscalls (Ej. fork())
   los hilos son creados a través de *bibliotecas de usuario*, el SO no los conoce a los ULTs
   #+END_COMMENT
*** Respuesta Correcta
   #+BEGIN_QUOTE
   FALSO.
   porque los ULTs se crean a partir de una *biblioteca de usuario* y el SO no las conoce
   #+END_QUOTE
** Pregunta 10
   #+BEGIN_QUOTE
   La creación y switcheo entre ULTs del mismo KLT/proceso es más liviano
   que la gestión de KLTs. Es V/F?
   #+END_QUOTE

   #+BEGIN_COMMENT
   Verdadero.
   Porque en la creación/switcheo entre ULTs el SO no interviene, por tanto no hay overhead
   
   mientras que la gestión de Procesos/KLTs interviene el SO
   #+END_COMMENT
*** Respuesta Correcta
   #+BEGIN_QUOTE
   Es VERDADERO, 
   porque al switchear entre ULTs no hay *cambio de contexto* (la biblioteca de ULTs guarda esa información)
   ni tampoco hay *cambio de modo* (porque al no cambiar de proceso, no se debe guardar el ctx de ese y restaurar el de otro proceso)
   #+END_QUOTE
* [WAITING] Cuestionario (6)
** Pregunta 1
   #+BEGIN_QUOTE
   Cual de los sig. podrian ser sintomas de que esta ocurriendo una *Condición de carrera*?
   
   a) Los procesos estan bloqueados y no pueden ejecutar
   b) Los procesos siguen ejecutando pero no pueden finalizar
   c) Los procesos pueden ejecutar pero tienen resultados erráticos (cambia según el orden de ejecución)
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) FALSO, esto es deadlock
   - b) FALSO, esto es livelock
   - c) Verdadero
   #+END_COMMENT
*** Respuesta correcta
   c) Los procesos pueden ejecutar pero tienen resultados erráticos (cambia según el orden de ejecución)
*** Observaciones
** Pregunta 2
   #+BEGIN_QUOTE
   Que condiciones son necesarias para que exista una *condición de carrera* ?
   
   a) dos o mas procesos/hilos accediendo al un mismo recurso comun
   b) dos o mas procesos/hilos accediendo a un recurso comun, ambos en modo lectura
   c) dos o mas procesos/hilos accediendo a un recurso comun, ambos en modo escritura
   d) dos o mas pocesos/hilos accediendo a un recurso comun en *forma concurrente*
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) Verdadero, y con al menos uno en modo escritura
   - b) Falso, porque no modificarían la sección crítica
   - c) Falso, con que uno esté en modo escritura es condición suficiente
   - d) Verdadero
   #+END_COMMENT
*** Respuesta correcta
   - a) dos o mas procesos/hilos accediendo al un mismo recurso comun
   - d) dos o mas pocesos/hilos accediendo a un recurso comun en *forma concurrente*

   *Observación:*
   - Para ambos casos es necesario *Sincronizar*
*** Respuestas INCORRECTAS
    - la b) y c) estaría mal, se cumple con que uno esté en modo escritura
*** Observaciones
** [#B] Pregunta 3
   #+BEGIN_QUOTE
   Cual de las sig. afirmaciones son correctas sobre la *Región Crítica* ?

   a) Dentro de la misma se suele aprovechar para acceder a varios recursos
      compartidos para ser más eficientes
   b) debe ser lo más chica posible
   c) la misma debe estar rodeada por un protocolo de sección de entrada/salida
   d) segun como este construida la seccion de entrada podria dejar entrar a uno
      o mas procesos a la región crítica
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) FALSO, se trata que la región crítica sea lo más chica posible
   - b) Verdadero
   - c) Verdadero
   - d) *FALSO, se trata que en la sección crítica cumpla con *mutua exclusión*, un proceso por vez
   #+END_COMMENT
*** Respuesta correcta
   - b) debe ser lo más chica posible
   - c) la misma debe estar rodeada por unprotocolo de seccion de entrada/salida
*** Respuestas INCORRECTAS
    - a) FALSO, porque se trata siempre de acceder a algo muy puntual como un solo recurso (ej. una variable), no a muchos recursos
    - d) FALSO, porque la idea es que cumpla con la *Mutua Exclusión* es decir solo un proceso por vez
*** Observaciones
** [#A] Pregunta 4
   #+BEGIN_QUOTE
   Que condiciones deberia cumplir una buena solución a la *Condición de Carrera* ?
   
   a) permitir que un proceso pueda ingresar a la SC eventualmente,
      que tarde mas o menos pero que NO genere *Starvation* (inanición)
   b) Sin importar cuantas veces un proceso necesite ingresa a la SC, pueda hacerlo
      sin problemas
   c) No debe condicionar el ingreso a la SC a otros procesos que no estén en la 
      sección de entrada
   d) Garantizar que solo un poceso pueda ingresar a la vez en la SC
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) Verdadero, esto cumpliría con "Espera limitada"
   - b)* Verdadero, esto cumpliría con "Velocidad Relativa"
   - c) Verdadero, esto cumpliría con "Progreso" (Ej. el ejemplo de los turnos)
   - d) Verdadero, esto cumpliría con "Mutua Exclusión"
   #+END_COMMENT
*** Respuesta correcta
    TODAS..
    - la a) hace referencia a la "espera limitada"
    - la b) hace referencia a la "velocidad relativa" de los procesos
    - la d) hace referencia a la *muta exclusión*
    - la c) hace referencia al *progreso* (recorda el ejemplo de turnos, en el que uno
    quería acceder y no podia, y debia esperar al otro que quizas no hacia nada
    relacionado a la SC, y lo LIMITA a progresar)
*** Observaciones
** [#B] Pregunta 5
   #+BEGIN_QUOTE
   Cuales de las sig. son opciones para garantizar *mutua exclusión* ?
   
   a) Solución de Peterson
   b) Semaforo mutex
   c) TEST_and_SET
   d) Monitores
   e) Deshabilitar Interrupciones
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) Verdadero, porque usa la solución de Turnos+Interesados
   - b) Verdadero, porque bloquea el acceso a la sección crítica (el recurso compartido)
   - c) Verdadero, además es a nivel de hardware
   - d) Verdadero, es similar al semáforo mutex, pero con una implementación más compleja + otras ventajas
   - e) Verdadero, porque el deshabilitar las interrupciones, evita que las instrucciones de la sección crítica sean interrumpidas
   #+END_COMMENT
*** Respuesta correcta
    todas..
*** Observaciones
    recordar que la c) de test_and_set es a nivel de hardware
** Pregunta 6
   #+BEGIN_QUOTE
   V o F?
   *Swap and Exchange* y *deshabilitar interrupciones* son opciones validas
   para solucionar el problema de la *condicion de carrera*.
   Sin embargo la 2da opcion NO siempre es recomendada
   #+END_QUOTE

   #+BEGIN_COMMENT
   Verdadero.
   la 2da no se recomienda, para entornos con multiprocesamiento (varios procesadores)
   porque el deshabilitar/habilitar las interrupciones en cada procesador es costoso
   #+END_COMMENT
*** Respuesta correcta
   #+BEGIN_QUOTE
    Verdadero,
    porque el de *deshabilitar interrupciones* NO se recomienda para un sistema
    con multiprocesadores, sino para uno.
   #+END_QUOTE
*** Observaciones
** Pregunta 7
   #+BEGIN_QUOTE
   Cual de los sig. valores de inicialización de *semaforos* son correctos?

   a) 1
   b) 10
   c) -1
   d) 0
   #+END_QUOTE
*** Respuesta correcta
   #+BEGIN_QUOTE
   a) 1, 
   en el caso que usemos un *semáforo mutex* (para que uno de los proceso se active,
   y empiecen a alternarse entre los procesos)
   ó un *semáforo binario* que esté inicialmente habilitado

   b) 10
   en el caso de que usemos un *semaforo contador*,

   d) 0
   en el caso que esperemos alguna condición
   #+END_QUOTE
*** Observaciones
** [#A] Pregunta 8
   #+BEGIN_QUOTE
   V o F?
   Las funciones de acceso al *Mutex* pueden ser implementadas *con bloqueo* y *sin bloqueo* (con espera activa).
   
   Sin embargo, *con bloqueo* es la forma más recomendada para favorecer la performance.
   #+END_QUOTE
*** Respuesta correcta
   #+BEGIN_QUOTE
    FALSO.
    Si se tratase de un sistema con un esquema de *monoprocesador*, se recomienda *con bloqueo*

    En la actualidad, NO se recomienda *con bloqueo*, porque todos los sistemas son con *multiprocesadores*,
    y no es eficiente en esos.
   #+END_QUOTE
*** Observaciones
** Pregunta 9
   #+BEGIN_QUOTE
   Si en un momento miramos el estado de los semaforos, y vemos que uno
   tiene un valor -4. Que podriamos deducir?

   a) Los semaforos se estan usando con una implementacion con *espera activa*
   b) Los semaforos se estan usando con una implementacion *con bloqueo*
   c) Hay un error con ese semaforo
   d) Hay 4 procesos en *estado bloqueado* en general en el sistema
   e) hay 4 procesos en *estado bloqueado* por ese semaforo
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) FALSO, si tuviese espera activa => cuando tuviese valor 0 se quedaría en un loop
   - b) Verdadero, cada vez que al semáforo se le aplicó un wait, éste decrementó su valor en 1
   - c) FALSO, un semáforo acepta valores negativos, y es la cant. de procesos bloqueados esperando a usar el recurso asociado al semáforo
        (pero no pueden ser inicializados con valor negativo)
   - d) *FALSO, hay 4 procesos bloqueados asociados a ese semáforo, no es en general e el sistema
   - e) Verdadero
   #+END_COMMENT
*** Respuesta correcta
   - b) Los semaforos se estan usando con una implementacion *con bloqueo*
   - e) hay 4 procesos en *estado bloqueado* por ese semaforo
*** Respuesta INCORRECTAS
   - a) porque con *espera activa* NUNCA tiene valores negativos
*** Observaciones
** [WAITING] [#A] Pregunta 10
   #+BEGIN_QUOTE
   V ó F ?
   El problema de *inversión de prioridades* podria ocurrir siempre que
   en un sistema que utilice *mutex* sobre sus recursos?
   #+END_QUOTE
*** Respuesta correcta
    FALSO.
*** Observaciones
   #+BEGIN_QUOTE
   Recordar que las condiciones que generan este problema eran 
   1. estemos usando recursos con *mutua exclusión*
   2. tener un *planificador* que elije el más prioritario
   #+END_QUOTE

   #+BEGIN_COMMENT
   <<DUDA>>:
   NO entendi muy bien.. (?)
   #+END_COMMENT
* Cuestionario (7)
** [WAITING] Pregunta 1
   #+BEGIN_QUOTE
   *Multiprocesamiento* implica:
   
   a) Procesamiento Distribuido 
   b) NS/NC
   c) Ninguna de las anteriores
   d) Multiprogramación
   #+END_QUOTE

   #+BEGIN_COMMENT
   <<DUDA>>:
   Por que Multiprocesamiento implíca Multiprogramación?
   La inversa es falsa, no?
   #+END_COMMENT
*** Respuesta correcta
   d) Multiprogramación
*** Observaciones
** Pregunta 2
   #+BEGIN_QUOTE
   Si los procesos interactúan compartiendo recursos del sistema, entonces:

   a. Es necesario sincronizar su uso, porque el SO no lo hace. 
   b. No es necesario sincronizar su uso, porque el SO los administra
   c. Ninguna de las anteriores
   d. NS/NC
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) Verdadero, se podría usar semáforos ó alguna solución de hardware
   - b) FALSO
   #+END_COMMENT
*** Respuesta correcta
   a. Es necesario sincronizar su uso, porque el SO no lo hace. 
*** Observaciones
** Pregunta 3
   #+BEGIN_QUOTE
   En el ejemplo de los incrementos de una misma variable entre dos ó mas hilos
   visto en clase

   a. Ninguna de las anteriores
   b. Puede haber problemas debido al uso de *variables del Stack* (pila)
   c. El comportamiendo es indefinido porque siempre se corromperán datos internos 
   d. NS/NC
   #+END_QUOTE
*** Respuesta correcta
   a. Ninguna de las anteriores
*** Observaciones
** [WAITING] [#A] Pregunta 4
   #+BEGIN_QUOTE
   En la *mutua exclusión*:

   a. Se pierde algo de la performance obtenida de la concurrencia
   b. Ninguna de las anteriores
   c. NS/NC
   d. Es obligatorio que dentro de la región crítica el proceso esté un tiempo reducido 
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) F
   - d) V
   #+END_COMMENT
*** Respuesta correcta
   a. Se pierde algo de la performance obtenida de la concurrencia

   #+BEGIN_COMMENT
   <<DUDA 1>>: Porque estaria mal la d) ???
   
   Rta: creo... que porque no es tema de la "mutua exclusión",
   si no de la condición de "espera limitada"
   #+END_COMMENT
*** Observaciones
** [#B] Pregunta 5
   #+BEGIN_QUOTE
   En las *soluciones de software* para *garantizar Mutua Exclusión*:

   Seleccione una:
   a. La performance es un factor clave que les juega en contra
   b. NS/NC
   c. Ninguna de las anteriores
   d. No existen algoritmos que garanticen la mutua exclusión en un 100% 
   #+END_QUOTE
*** Respuesta correcta
   a. La performance es un factor clave que les juega en contra

   #+BEGIN_COMMENT
   Porque todas tienen espera activa.. La de Turnos, la de Interesados,
   
   y también la *solución de Peterson* que es la mejor de las de Software
   (porque complementa la de turnos + interesados)
   #+END_COMMENT
*** Observaciones
** Pregunta 6
   #+BEGIN_QUOTE
   En las *soluciones de mutua exclusión por hardware*:

   a. Ninguna de las anteriores
   b. Las instrucciones como «test and set» pueden ser igualmente interrumpidas 
   c. NS/NC
   d. La deshabilitación de las interrupciones es un mecanismo ineficiente pero seguro
   #+END_QUOTE

   #+BEGIN_COMMENT
   - b) Falso, son atómicas y son a nivel de hardware, no pueden ser interrumpidas
   - c) Verdadero, es ineficiente en especial para sistemas con multiprocesadores
   #+END_COMMENT
*** Respuesta correcta
   d. La deshabilitación de las interrupciones es un mecanismo ineficiente pero seguro
*** Observaciones
** [WAITING] [#A] Pregunta 7
   #+BEGIN_QUOTE
   Al usar semáforos:

   a. Al llamar a signal(s), se despierta un proceso si el semáforo no quedó positivo
   b. Al llamar a signal(s), se despierta a un proceso si el semáforo quedó positivo
   c. Ninguna de las anteriores 
   d. NS/NC
   #+END_QUOTE

   #+BEGIN_COMMENT
   - a) Falso
   - b) Verdadero 

   Ej.
   1) semA=-2
   2) signal(semA)
   3) semA=-1 (positivo) ---> (???) <<DUDA>>
   #+END_COMMENT
*** Respuesta correcta
   a. Al llamar a signal(s), se despierta un proceso si el semáforo no quedó positivo
*** Observaciones
** Pregunta 8
   #+BEGIN_QUOTE
   La «atomicidad» de las funciones de manejo de semáforos se logra:

   a. Ninguna de las anteriores
   b. Usando otros semáforos
   c. NS/NC
   d. Mediante el hecho de que dichas funciones son instrucciones de procesador
   e. Mediante alguna solución de software o hardware 
   #+END_QUOTE

   #+BEGIN_COMMENT
   - b) FALSO
   - d) FALSO
   - e) Verdadero
   #+END_COMMENT
*** Respuesta correcta
   e. Mediante alguna solución de software o hardware 
*** Observaciones
** [#A] Pregunta 9
   #+BEGIN_QUOTE
   En los *monitores*:

   a. Ninguna de las anteriores 
   b. Se pueden resolver *problemas de coordinación*, pero no de mutua exclusión
   c. Se pueden resolver *problemas de mutua exclusión*, pero no de coordinación
   d. NS/NC
   #+END_QUOTE
*** Respuesta correcta
   a. Ninguna de las anteriores 
*** Observaciones
* Importante
** IO Bound
    Los I/O Bound (o Limitados por E/S) sus ráfagas de CPU son cortas
** Hilos
*** Crear/Switchear de ULTs, Biblioteca de ULTs
   - los ULTs se crean a partir de una *biblioteca de usuario* y el SO no las conoce
   - al crear/switchear entre ULTs no hay *cambio de contexto* (la biblioteca de ULTs guarda esa información)
   - al crear/switchear no hay *cambio de modo* (porque al no cambiar de proceso, no se debe guardar el ctx de ese y restaurar el de otro proceso)

   *Observación:*
   - los ULTs NO son creados a través de ~syscalls~ como los procesos (Ej. fork())
** Sincronización
*** Condiciones para solucionar una Condición Carrera
   - _ESPERA LIMITADA_: Permitir que un proceso pueda ingresar a la SC eventualmente, que tarde mas o menos pero que NO genere *Starvation* (inanición)
   - _VELOCIDAD_RELATIVA_: Sin importar cuantas veces un proceso necesite ingresa a la SC, pueda hacerlo sin problemas
   - _PROGRESO:_ No debe condicionar el ingreso a la SC a otros procesos que no estén en la sección de entrada
   - _MUTUA EXCLUSION:_ Garantizar que solo un poceso pueda ingresar a la vez en la SC
*** Mutua Exclusión
   - En la *mutua exclusión*, se pierde algo de la performance obtenida de la concurrencia
*** Opciones que garantizan la Mutua Exclusión
   #+BEGIN_QUOTE
   - a) _Solución de Peterson_: (usa la solución de turnos + la solución de interesados)
   - b) _Semáforo mutex_: (bloquea el acceso a la sección crítica, osea el recurso compartido)
   - c) _TEST_and_SET_: (además es a nivel de hardware, y hace que las operaciones sean atómicas)
   - d) _Monitores_: (es similar al mutex, pero con una implementación más compleja, y más ventajas)
   - e) _Deshabilitar Interrupciones_: (evita que las instrucciones de la SC sean interrumpidas con las de otro proceso)
   #+END_QUOTE
*** Soluciones de software para garantizar Mutua Exclusión
   - La performance es un factor clave que les juega en contra (porque todas tienen *espera activa*)
   - La solución de Turnos, la de Interesados,y hasta la Solución de Peterson tienen espera activa
     (la de peterson integra la de turnos+interesados)
*** Semáforos Implementación - Con Bloqueo Vs Sin Bloqueo
   #+BEGIN_QUOTE
   _Sin *ESPERA ACTIVA* (con bloqueo)_: <- por default
   1) Se recomienda para sistemas con esquemas de monoprocesador
   2) por default, el SO bloquea los procesos asociados al semáforo, esperando para entrar a la SC
   3) Se usa ~phtreads_mutex_t~
      
   _Con *ESPERA ACTIVA* (sin bloqueo)_:
   1) genera overhead porque se queda en un while(1) preguntando a cada rato
   2) se recomienda para sistemas con multiprocesadores (/más de un CPU/)
   3) se reducen los cambios de contexto, porque evitamos el bloqueo/desbloqueo de procesos asociados a un semáforo que esperan usar un recurso
   4) Se usa ~phtreads_spinlock_t~
   #+END_QUOTE
     
   *Observaciones:*      
    - Si se tratase de un sistema con un esquema de *monoprocesador*, se recomienda *con bloqueo*
    - Actualmente, NO se recomienda *con bloqueo*, porque todos los sistemas son con *multiprocesadores*, y no es eficiente en esos.
*** Semáforos - Espera activa
   Las situaciones que pueden ser mas eficiente usar ~pthreads_spinlocks_t~ serían
   + Cuando hay más de 1 CPU (/sistema multiprocesador/)
   + Cuando la *Sección Crítica* es chica (//)

    #+BEGIN_QUOTE
    El proceso en "espera activa" continúa su ejecución más rápido,
    nos ahoramos el bloqueo/desbloqueo y los cambios de contexto
    #+END_QUOTE
** Interrupciones
*** Que guardar previo a atender una Interrupción
   #+BEGIN_QUOTE
   El valor de los registros del CPU: (PC) Program Counter, y (PSW) Program Status Word
   
   El (PC, Program Counter) porque guarda la dirección de memoria
   de la siguiente instrucción a ejecutar, para continuar el 
   ciclo de la instrucción

   y el (PSW, Program Status Word) porque guarda el bit que
   representa el modo de ejecución (usuario/kernel)
   #+END_QUOTE
*** Cuando atender Interrupciones
   Suponiendo que NO están deshabilitadas, se atienden luego de finalizar el atender la instrucción en curso
*** Interrupción de Clock
**** El SO no lanza la interrupción
   - En RR, _el SO no lanza la *interrupción de clock*_, sino que atiende la *interrupción de clock*
**** El SO toma el control del Procesador
   - La *interrupción de Clock* permite que el SO, tome el control del procesador 
     para que realice alguna tarea. Esa tarea puede ser el realizar un cambio de proceso, o no.
   - *El procesador no realiza cambios de proceso*
** Algoritmo de Feedback
    Para el *algoritmo de tipo Feedback* es necesario saber también:
    - a qué cola ingresan los procesos nuevos?
    - cuáles son las prioridades entre colas?
    - hay desalojo entre ellas?
    - cuál es el criterio para pasar de una cola de mayor prioridad?
    - se puede pasar de una cola de menor prioridad a una de mayor?
** Planificadores
*** Planificador Corto Plazo
   - Es invocado cuando se realiza una llamada al sistema o una interrupción. 
*** Planificador de Largo Plazo y Mediano Plazo
   #+BEGIN_QUOTE
   Los *planificadores de largo y mediano plazo* pueden afectar el orden de los procesos
   En lista de procesos listos para ejecutar
   #+END_QUOTE
** Starvation (inanición)
   *Starvation* es una problemática que "podría" nunca ocurrir, independientemente del algoritmo utilizado.
* Metricas
   - El "response time" es el tiempo que el usuario espera desde que realiza una operación hasta recibe alguna respuesta del sistema.
