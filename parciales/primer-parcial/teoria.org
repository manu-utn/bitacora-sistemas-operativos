#+TITLE: Parciales - Teoría
* Parciales 2019
** Turno Mañana
*** Pregunta 1
    #+BEGIN_QUOTE
    Compare los algoritmos *HRRN*, *SJF* con desalojo y sin desalojo en términos de criterio de
    selección, posible desalojo, penalización procesos cortos/largos, *Overhead* , y *Starvation*
    #+END_QUOTE

    *Respuesta:*
    El algoritmo *HRRN* selecciona aquellos que tenga un ratio de respuesta más rápida,
    y realizar esos cálculos *overhead*, además que el CPU estará siendo ocupada mayor tiempo.

    El *SJF* c/desalojo selecciona a los procesos con menor estimación de ráfaga de cpu
    produce *inanición* en aquellos procesos que su estimación de rafaga de cpu sea alta,
    ya que se prioriza menor %.
    Este produce más *overhead* que el s/desalojo porque compara cada proceso al momento de decidir
    cual desalojar, en cambio el otro solo evalua el de menor ráfaga de cpu.

    El *SJF* s/desalojo también selecciona a los procesos con menor estimación de ráfaga de CPU.
*** [DOING] [#A] Pregunta 2
    #+BEGIN_QUOTE
    Describa brevemente los tipos de semáforos y qué problema resuelve cada uno. ¿Cómo
    solucionaría un *problema de productor/consumidor* con un buffer infinito utilizando semáforos?
    #+END_QUOTE

    *Respuesta:*
    Los tipos de semáforos que existen son
    1. _Semáforo Contador:_ Limita la cantidad de instancias de un recurso
    2. _Semáforo Mutex_: Soluciona la *mutua exclusión*, impide que por *condición de carrera* varios procesos accedan 
      a un recurso compartido al mismo tiempo
    3. _Semáforo Binario_: Es un caso particular del *mutex* y permite controlar un orden de ejecución entre 
      procesos. Tiene dos estados (0=libre, 1=ocupado) y permiten o no avanzar a un proceso.

    Un *semáforo mutex* para proteger el buffer que es la sección compartida entre dichos procesos.
    Y un *semáforo contador* para que el *proceso productor* pueda generar N instancias de recursos, y
    el *proceso consumidor* sepa cuanto puede utilizar. (???)

    <<DUDA 1>>: El semaforo contador no servía también para limitar la cantidad de accesos a un recurso?
    <<DUDA 2>>: No serviría también un semaforo binario, para que el proceso productor le avise al proceso consumidor,
    y luego viceversa?
    <<DUDA 3>>: Esta ok lo del semaforo contador con N instancias en el proceso productor? me suena raro (?)
*** [TODO] [#B] Pregunta 3
    #+BEGIN_QUOTE
    En un sistema que tiene *modos de ejecución* para garantizar la protección, indique.
    a. ¿Cómo sería la forma correcta de realizar una operación sobre el HW?
    b. Indique una forma “incorrecta” y explique por qué no sería permitida.
    #+END_QUOTE

    *Respuesta:*
    a. Lo correcto sería solicitar realizar la operación mediante ~syscalls~ para que el SO intervenga,
       realice el *cambio de modo* (a modo kernel) y este luego ejecute la operación.
    b. Lo incorrecto sería intentar ejecutar una *instrucción privilegiada* en modo usuario,
       ya que NO podríamos, solo pueden ser ejecutadas en *modo kernel*
*** [TODO] [#B] Pregunta 5 
    *Respuesta:*

    #+BEGIN_QUOTE
    Explique cómo el *planificador de corto plazo* podría llegar a generar una *condición de carrera*.
    Proponga una forma de solucionarla, sin soporte del SO, que pueda ser aplicado en entornos con
    múltiples procesadores
    #+END_QUOTE
** Turno Tarde
*** Pregunta 1
    #+BEGIN_QUOTE
    ¿Cuál es la diferencia entre una Syscall y una función Wrapper? ¿En qué caso utilizaría cada
    una y por qué?
    #+END_QUOTE
    
    *Respuesta Elegida:*
    Las ~syscall~ son operaciones para solicitar servicios al SO, no son tan expresivas y de fácil de uso
    para el usuario.
    Los ~wrapper~ (de syscalls) son a nivel de usuario, pueden hacer llamadas a ~syscall~ de manera más fácil para
    el usuario y permiten la *portabilidad* (usar en distintos SO, y funcionen del mismo modo)
    
    Los ~wrappers~ se pueden utilizar para pedir datos a un dispositivo de E/S (Ej. al disco para lectura/escritura)
*** [TODO] Pregunta 3
    #+BEGIN_QUOTE
    Definir el concepto de sección crítica. ¿Qué condiciones debe cumplir? Mostrar un ejemplo
    del uso de soluciones hardware dentro de las primitivas wait/signal.
    #+END_QUOTE
    
    *Respuesta:*
    La *sección crítica* es aquella que puede verse afectada por una *condición de carrera* entre varios recursos
    que intentan acceder a esta en modo de escritura/lectura. Esto genera comportamientos indefinidos, erráticos
    que son no *deterministas* es decir puede dar resultados que uno no deseaba.
    La misma puede ser una variable, un conjunto de variables, una estructura, .. Aunque se recomienda que 
    sea lo más reducida posible.

    Las condiciones que debe cumplir son
    1. _Mutua exclusión_: sólo un proceso por vez pueda acceder al recurso
    2. _Velocidad Relativa_: el tiempo de ejecucion limitado, para favorecer la *multiprogramación*
    3. _Espera Limitada_: que estén esperando un tiempo reducido para evitar la *inanicion*
    4. _Progreso_: si el recurso está disponible, deben poder acceder procesos/hilos y si alguno 
       está fuera de la zona critica, no debería impedir el acceso a la misma a otros.
      
    *Observaciones:*
    - La *multiprogramación* permite que varios procesos puedan ejecutarse concurrentemente (en mismos intervalos
      de tiempo, que a la perspectiva del usuario aparenta que se ejecutan en paralelo, pero NO)
    - La *inanición* (ó starvation) de un proceso surje cuando este NUNCA es ejecutado, y se puede deber a que el planificador
      priorize a otros procesos.

    #+BEGIN_SRC C
      wait(sem){
        deshabilitar_interrupciones()    // para que ningún proceso lo interrumpa
        sem--

        if( sem < 0 ) bloquear_proceso() // si algún proceso intenta acceder al recurso, deberá esperar
        habilitar_interrupciones()
      }

      signal(sem){
        deshabilitar_interrupciones()        // para que ningún proceso lo interrumpa
        sem++

        if (sem <= 0) desbloquear_proceso()
        habilitar_interrupciones()
      }
    #+END_SRC
*** [TODO] Pregunta 4
    #+BEGIN_QUOTE
    Verdadero o falso:
    1. Utilizando semáforos en hilos ULT, no requieren realizar un cambio de modo para
       ejecutar las operaciones de wait/signal.
    2. Para compartir memoria entre procesos o entre KLTs se necesita intervención del
       SO. Entre ULTs no es necesario, debido a que se gestionan en espacio de usuario.
    #+END_QUOTE

    *Respuesta:*
    +1. Verdadero, pueden utilizar funciones de la biblioteca de ULT+
    +2. Falso, no se puede compartir memoria entre procesos+

    1. Falso, porque las operaciones ~wait~ y ~signal~ son ~syscall~
    2. Falso, pueden compartir memoria sin que e SO intervenga (Ej. variables globales)
*** Pregunta 5
    #+BEGIN_QUOTE
    Los algoritmos de planificación con desalojo ¿Qué eventos tienen en cuenta para la
    re-planificación? ¿Por qué los algoritmos sin desalojo no?
    #+END_QUOTE

    *Respuesta:*
    Los algoritmos como el SJF con desalojo se tiene en cuenta eventos como
    - Interrupcion por Fin de IO (un proceso se bloquea)
    - Finalización de un proceso (se libera el cpu)
    - Un nuevo proceso (de la cola de New)

    En el caso de RR y VRR, los eventos son
    - Interrupción por fin de quantum

    En los algoritmos sin desalojo como el FIFO o el SJF sin desalojo,
    no se tiene en cuenta esos eventos porque el objetivo es que continuen los procesos
    hasta que finalicen. Se prioriza los procesos CPU-BOUND
* Parciales 2018
** Turno Mañana
*** Pregunta 1
    #+BEGIN_QUOTE
    ¿Es consciente en algún momento el proceso del hecho de quedar bloqueado o continuar su
    ejecución? En caso afirmativo explique cómo, y en caso negativo indique por qué.
    #+END_QUOTE

    *Respuesta:*
    El proceso no se entera en que estado se encuentra, es el SO el que lo sabe y decide
*** [#A] Pregunta 3
    #+BEGIN_QUOTE
    ¿Qué problema resuelve un semáforo mutex? ¿De qué otra forma podría resolver el mismo problema?
    Si en cierto momento el valor de dicho semáforo es negativo, ¿qué implicancias puede asumir?
    #+END_QUOTE

    *Respuesta:*
    El *semáforo mutex* resuelve el problema de la *mutua exclusión* por *condición de carrera*
    que se produce cuando multiples procesos intentan acceder a la misma instancia de recurso
    en modo de escritura/lectura, evitando que haya comportamiento no determinista es decir
    que sabremos que el resultado final de una operación será la esperada y no producto de un error.

    Una alternativa sería con *instrucciones atómicas* como ~test and set~ y ~swap and exchange~

    Si el *semáforo mutex* tiene valor negativo, es porque en la implementación del ~wait~
    se definió que sería una operación *bloqueante*, por tanto habrá algun proceso bloqueado 
    esperando a acceder al recurso compartido.
    
    +Una alternativa podría ser.. utilizar variables globales y bucle como ~while~ que tenga como+ 
    +condición de corte a centinela, permitiendo no utilizar dicha variable+
    +Si el valor es negativo, quiere decir que no es un mutex, si no un semaforo contador.+
*** [#A] Pregunta 4
    #+BEGIN_QUOTE
    V o F
    Los *semáforos*, aún bien usados, pueden llegar a generar problemas en sistemas que utilicen
    *planificadores de corto plazo* basados en prioridades.
    #+END_QUOTE

    *Respuesta:*
    Verdadero. Puede suceder que el *planificador* _priorize procesos de menor prioridad_,
    quedando _procesos de mayor prioridad en cola de ready esperando_ a su ejecución.
*** [#B] Pregunta 5
    #+BEGIN_QUOTE
    Describa cómo afecta en el comportamiento de un sistema el tamaño del *quantum*. ¿Afecta de la
    misma manera en *RR* que en *VRR*?
    #+END_QUOTE

    *Respuesta:*
    No afecta de la misma manera a ambos.
    Si fuese un quantum chico, en un *RR* habrá más *overhead* porque tendrá pequeños intervalos
    y en cada *interrupción de quantum* tendrá que intervenir el SO, y esas interrupciones 
    se realizan por *interrupciones de timer* a nivel de hardware.
    Si tuviese un quantum más grande, el *RR* se convierte en *FIFO*.
    
    Un *VRR* un quantum grande, se convierte en un *RR*.
    Y si este tuviese un quantum chico, tendría el mismo problema de *overhead* que el *RR*
    Si fuese un quantum más grande, tanto en *RR* como *VRR* habrá *inanición*.

    +Si fuese un quantum chico en un *VRR* los procesos IO-BOUND se verían beneficiados.+
** [TODO] Turno Tarde
*** [TODO] [#A] Pregunta 1
    #+BEGIN_QUOTE
    Compare los algoritmos *RR*, *VRR* y *HRRN* en términos de *Overhead*, *Monopolización* de la
    CPU y *Starvation*
    #+END_QUOTE    

    #+BEGIN_COMMENT
    Mi respuesta difería un tanto de la resolución.. (???)

    En el *RR* y *VRR* si el tamaño de *quantum* es chico, ambos producirán *overhead*
    Si tuviesen un *quantum* grande, se produciría *monopolización* del CPU y también
    también *inanición* (ó starvation) porque sólo una *interrupción por fin de quantum*
    los desalojaría a los procesos del CPU.

    En el caso del *HRRN* al tener que calcular en cada momento de replanificación 
    el *ratio* de respuesta de cada proceso, produce un gran *overhead*
    #+END_COMMENT

    *Respuesta de la resolución:*
    |------------------------+------+-------+--------|
    |                        | R    | VRR   | HRRN   |
    |------------------------+------+-------+--------|
    | Overhead               | maso | mucho | mucho  |
    | Monopolización del CPU | NO   | NO    | quizas |
    | Starvation             | NO   | NO    | NO     |
    |------------------------+------+-------+--------|
*** Pregunta 2
    #+BEGIN_QUOTE
    ¿Quiénes pueden crear o finalizar Procesos en un sistema? ¿Cómo lo hacen? ¿Qué le sucede
    al proceso hijo si su padre finaliza inesperadamente?
    #+END_QUOTE

    *Respuesta:*
    Es el SO quien tiene la potestad de crear/finalizar procesos en el sistema,
    los procesos pueden solictar al SO su creación mediante ~syscalls~ como el ~fork~
    para el caso de crear procesos hijos. Para la finalización propia pueden utilizar
    otras llamadas al sistema como ~exit~ y ~kill~ si quisieran realizarlo con otro proceso.

    Si el *proceso padre* finaliza antes que su *proceso hijo*, este segundo puede seguir
    ejecutandose de manera independiente, también conocido por *proceso huerfano* 
    (es decir un proceso hijo sin proceso padre)
    Si el caso fuese al revés, el *proceso padre* se conocería como *proceso zombie*.
    
    +Si el *proceso padre* finaliza antes que su *proceso hijo*, este también finalizará.+
*** [#A] Pregunta 4
    #+BEGIN_QUOTE
    V o F
    a. El hecho de utilizar un *semáforo* implica un cambio de *modo de ejecución*.
    b. El *planificador de corto plazo* según sus decisiones modifica el *grado de multiprogramación*
    del sistema
    #+END_QUOTE

    *Respuesta:*
    a) VERDADERO. Porque los semáforos utilizan ~syscall~ (llamadas al sistema) como lo son ~wait~ y ~signal~
    en donde interviene el SO para luego pasa a *modo kernel*

    b) FALSO. Si el SO tuviese *planificador de largo* quien podría afectar el *grado de multiprogramación*
    porque es quien decide que proceso nuevo ingresar o sacar procesos de memoria (eligiendo quienes irán
    a la cola de nuevos, y quienes finalizan)
    También podría ser el *planificador de mediano plazo* porque decide sacar procesos de memoria
    para pasarlos a disco, en caso que pasaran a un estado de suspensión.

    #+BEGIN_COMMENT
    +a) FALSO. Utilizar semáforos implica poder cambiar el orden de ejecución+
    +de los procesos (ej. semáforo binario) ó limitar el acceso a una instancia+
    +de recurso (semáforo mutex) ó limitar las instancias de un recurso (semáforo contador)+

    +b) VERDADERO. El grado de multiprogramación indica la cantidad de procesos que pueden+
    +estar ejecutando concurrentemente, si el pcp utilizara un algoritmo *FIFO* ó *RR* con+
    +un quantum grande, podría afectar la cantidad de procesos que se ejecutan de manera concurrente.+
    #+END_COMMENT
*** [TODO] [#A] Pregunta 5
    #+BEGIN_QUOTE
    Describa brevemente qué ocurre cuando se invoca una ~syscall~ desde un proceso en 
    *modo usuario* y cómo se atiende la misma.
    #+END_QUOTE

    *Respuesta:*
    1. Se genera una *interrupción de software*
    2. El SO deja de atender por un momento el proceso que estaba en ejecución
    3. El SO Guarda en el PCB el CXT del proceso en ejecución
    4. El SO atiende la syscall
    5. Hay un cambio de modo (Modo usuario -> Modo kernel)
    6. Se ejecuta
